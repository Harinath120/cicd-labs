{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"cipipeline/","text":"Using Docker to Simplify CI Pipelines In this Lab, you will learn how to prepare jenkins for docker agent based build, refactoring maven jobs with docker agent and how to build nodejs app with docker. How to write jenkinsfile for python based vote app and how to troubleshoot docker agent jobs, pull requests, code review and merge to master branch and you have assignment as well. Preparing jenkins for docker agent based builds Here you will learn, how to prepare your jenkins server for docker based build, refer docker-with-pipeline document. Create docker-pipe-01 pipeline job in your jenkins. In configuration page, mention the following test code in jenkins script and save the configuration and build it. pipeline { agent { docker { image 'node:7-alpine' } } stages { stage('Test') { steps { sh 'node --version' } } } } If you run the build, it shows build will be failed because docker is not installed on your jenkins container, so you need to install docker inside the jenkis container and use the following command to install docker inside jenkins container. * docker ps * docker exec -u root -it jenkins bash * apt-get update * apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common * curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add - * apt-key fingerprint 0EBFCD88 * add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable\" * apt-get update * apt-get install docker-ce docker-ce-cli containerd.io Refer the docker install documentation for docker-install debian. After installing docke, run the following commands to check the docker version. * which docker * docker version Run the hello world container inside the jenkins container to validate docker. docker run hello-world Now run the build, agin you will get permission denied error, because jenkins user not a part of docker group. use following command inside jenkins container to add jenkins user into docker group and validate. * usermod -a -G docker jenkins * docker ps After adding jenkins user to docker group, exit from jenkins container and restart the container by using following command. docker restart jenkins Goto jenkins page and build the job, the pipeline will be successfull and your jenkisn serever is ready to run docker based build. Refactoring maven jobs with docker agent","title":"Using Docker to Simplify CI Pipelines"},{"location":"cipipeline/#using-docker-to-simplify-ci-pipelines","text":"In this Lab, you will learn how to prepare jenkins for docker agent based build, refactoring maven jobs with docker agent and how to build nodejs app with docker. How to write jenkinsfile for python based vote app and how to troubleshoot docker agent jobs, pull requests, code review and merge to master branch and you have assignment as well.","title":"Using Docker to Simplify CI Pipelines"},{"location":"cipipeline/#preparing-jenkins-for-docker-agent-based-builds","text":"Here you will learn, how to prepare your jenkins server for docker based build, refer docker-with-pipeline document. Create docker-pipe-01 pipeline job in your jenkins. In configuration page, mention the following test code in jenkins script and save the configuration and build it. pipeline { agent { docker { image 'node:7-alpine' } } stages { stage('Test') { steps { sh 'node --version' } } } } If you run the build, it shows build will be failed because docker is not installed on your jenkins container, so you need to install docker inside the jenkis container and use the following command to install docker inside jenkins container. * docker ps * docker exec -u root -it jenkins bash * apt-get update * apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common * curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add - * apt-key fingerprint 0EBFCD88 * add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable\" * apt-get update * apt-get install docker-ce docker-ce-cli containerd.io Refer the docker install documentation for docker-install debian. After installing docke, run the following commands to check the docker version. * which docker * docker version Run the hello world container inside the jenkins container to validate docker. docker run hello-world Now run the build, agin you will get permission denied error, because jenkins user not a part of docker group. use following command inside jenkins container to add jenkins user into docker group and validate. * usermod -a -G docker jenkins * docker ps After adding jenkins user to docker group, exit from jenkins container and restart the container by using following command. docker restart jenkins Goto jenkins page and build the job, the pipeline will be successfull and your jenkisn serever is ready to run docker based build.","title":"Preparing jenkins for docker agent based builds"},{"location":"cipipeline/#refactoring-maven-jobs-with-docker-agent","text":"","title":"Refactoring maven jobs with docker agent"},{"location":"devdeploycompose/","text":"Deploy to dev with Docker Compose Here is what you are going to learn in this chapter, You would begin by learning how docker compose could help launch a monitoring stack. understand the docker compose spec version 1 Keep adding services to docker compose Refactor the compose file with version3 syntax Create a consolidated jenkins pipeline and start deploying to a integrated dev environment with docker compose Creating docker compose spec cd example-voting-app file: docker-compose.yaml vote: build: ./vote command: python app.py links: - redis:redis ports: - 80 redis: image: redis:alpine worker: build: ./worker dockerfile: Dockerfile links: - redis:redis docker-compose config docker-compose build docker-compose build ( observe caching ) docker-compose up -d docker-compose ps Additional Commands docker-compose images docker-compose logs docker-compose logs worker docker-compose pull docker-compose exec vote ps docker-compose stop docker-compose down Refactoring docker compose with v3 spec file: docker-compose.yaml Replace xxxx with your docker hub id. version: \"3.7\" volumes: db-data: networks: instavote: driver: bridge services: vote: image: xxxx/vote:latest ports: - 5000:80 depends_on: - redis networks: - instavote redis: image: redis:alpine networks: - instavote db: image: postgres:9.4 volumes: - \"db-data:/var/lib/postgresql/data\" networks: - instavote result: image: xxxxx/result:latest ports: - 5001:4000 depends_on: - db networks: - instavote worker: image: xxxx/worker:latest depends_on: - redis - db networks: - instavote Adding deploy to dev with docker compose Add a deploy to dev stage to Jenkinsfile stage('deploy to dev'){ agent any when{ branch 'master' } steps{ echo 'Deploy instavote app with docker compose' sh 'docker-compose up -d' } }","title":"Lab 7 - Deploy to Dev with Compose"},{"location":"devdeploycompose/#deploy-to-dev-with-docker-compose","text":"Here is what you are going to learn in this chapter, You would begin by learning how docker compose could help launch a monitoring stack. understand the docker compose spec version 1 Keep adding services to docker compose Refactor the compose file with version3 syntax Create a consolidated jenkins pipeline and start deploying to a integrated dev environment with docker compose","title":"Deploy to dev with Docker Compose"},{"location":"devdeploycompose/#creating-docker-compose-spec","text":"cd example-voting-app file: docker-compose.yaml vote: build: ./vote command: python app.py links: - redis:redis ports: - 80 redis: image: redis:alpine worker: build: ./worker dockerfile: Dockerfile links: - redis:redis docker-compose config docker-compose build docker-compose build ( observe caching ) docker-compose up -d docker-compose ps","title":"Creating docker compose spec"},{"location":"devdeploycompose/#additional-commands","text":"docker-compose images docker-compose logs docker-compose logs worker docker-compose pull docker-compose exec vote ps docker-compose stop docker-compose down","title":"Additional Commands"},{"location":"devdeploycompose/#refactoring-docker-compose-with-v3-spec","text":"file: docker-compose.yaml Replace xxxx with your docker hub id. version: \"3.7\" volumes: db-data: networks: instavote: driver: bridge services: vote: image: xxxx/vote:latest ports: - 5000:80 depends_on: - redis networks: - instavote redis: image: redis:alpine networks: - instavote db: image: postgres:9.4 volumes: - \"db-data:/var/lib/postgresql/data\" networks: - instavote result: image: xxxxx/result:latest ports: - 5001:4000 depends_on: - db networks: - instavote worker: image: xxxx/worker:latest depends_on: - redis - db networks: - instavote","title":"Refactoring docker compose with v3 spec"},{"location":"devdeploycompose/#adding-deploy-to-dev-with-docker-compose","text":"Add a deploy to dev stage to Jenkinsfile stage('deploy to dev'){ agent any when{ branch 'master' } steps{ echo 'Deploy instavote app with docker compose' sh 'docker-compose up -d' } }","title":"Adding deploy to dev with docker compose"},{"location":"dockerfile/","text":"Packaging with Docker In addition to helping the process of building and testing software, docker could also provide a standard packaging format i.e. docker images. Along with this packaging format, comes the distribution mechanism i.e. docker image registries. In this lab you are going to learn, about Docker\u2019s standard imaging format How to test build docker images manually Learn how to write Dockerfiles understand the automated, iterative docker image process add docker packaging stage to the jenkins pipeline create per stage agent configurations in Jenkinsfile Registering with the DockerHub Since you are going to start working with the registry, build and push images to it later, its essential to have your own account on the registry. For the purpose of this tutorial, you are going to use the hosted registry i.e. Dockerhub. Steps to create Dockerhub account Step 1: Visit the following link and sign up with your email id https://hub.docker.com/ Step 2: Check your email inbox and check the activation email sent by docker team Step 3: After clicking on the activation link, you will be redirected to a log in page. Enter your credentials and log in You will be launched to Dockerhub main page. Now the registration process is complete and you have account in Dockerhub! Lab: Building Docker Images - A manual approach Before you start building automated images, you are going to create a docker image by hand. you have already used the pre built image from the registry in the last session. In this sub section, you are going to create an image with worker application installed. Since worker is a java based application, and needs maven to build it, you will base our work on existing official image for maven . Clone Repository for Java worker app git clone https://github.com/schoolofdevops/example-voting-app.git Launch an intermediate container to install worker app Create a Container with schoolofdevops/voteapp-mvn:v1 image docker run -idt --name build maven:3.6.1-jdk-8-slim sh Copy over the Source Code cd example-voting-app/worker docker container cp . build:/app Connect to container to compile and package the code docker exec -it build sh mvn package Verify jarfile has been built ls target/ java -jar target/worker-jar-with-dependencies.jar [sample output] /app # java -jar target/worker-jar-with-dependencies.jar Waiting for redis Waiting for redis Waiting for redis Waiting for redis Waiting for redis Waiting for redis ^c [use ^c to exit] The above is the expected output. The worker app keeps waiting for redis and then later db in a loop. Move the artifact, remove source code mv target/worker-jar-with-dependencies.jar /run/worker.jar rm -rf /app/* exit Commit container to an image Exit from the container shell Note container ID Commit the container into a image as, docker container commit build <docker hub user id >/worker:v1 Test before pushing by launching container with the packaged app docker run --rm -it <docker hub user id >/worker:v1 java -jar /run/worker.jar Push Image to registry Before you push the image, you need to be logged in to the registry, with the docker hub id created earlier. Login using the following command, docker login To push the image, first list it, docker image ls [Sample Output] REPOSITORY TAG IMAGE ID CREATED SIZE initcron/worker v2 90cbeb6539df 18 minutes ago 194MB initcron/worker v1 c0199f782489 34 minutes ago 189MB To push the image, docker push <dockrhub user id>/worker:v1 Lab: Building Images with Dockerfile Now, lets build the same image, this time with Dockerfile. To do this, create a file by name Dockerfile in the root of the source code. file: example-voting-app/worker/Dockerfile FROM maven:3.6.1-jdk-8-slim WORKDIR /app COPY . . RUN mvn package && \\ mv target/worker-jar-with-dependencies.jar /run/worker.jar && \\ rm -rf /app/* CMD java -jar /run/worker.jar Lets now build the image cd example-voting-app/worker docker image build -t <dockrhub user id>/worker:v2 . docker image ls Try building again, docker image build -t <dockrhub user id>/worker:v2 . This time, it does not build everything, but uses cache. Testing the image docker container run --rm -it <dockrhub user id>/worker:v2 Tag the image as latest, docker image tag <dockrhub user id>/worker:v2 <dockrhub user id>/worker:latest docker image ls Finally, publish it to the registry, docker image push <dockrhub user id>/worker:latest docker image push <dockrhub user id>/worker Adding docker build stage to Jenkinsfile Add username/password type credential to Jenkins with name dockerlogin . Do do so, browse to Jenkins -> Credentials -> Jenkins -> Global Credentials -> Add Credentials -> Username and password . Ensure you add the dockerhub login and password with id as dockerlogin . Refactor the Jenkinsfile for worker app by adding the following stage file: worker/Jenkinsfile stage('docker-package'){ agent any steps{ echo 'Packaging worker app with docker' script{ docker.withRegistry('https://index.docker.io/v1/', 'dockerlogin') { def workerImage = docker.build(\"xxxx/worker:v${env.BUILD_ID}\", \"./worker\") workerImage.push() workerImage.push(\"latest\") } } } } You have configured the pipelines to run with docker agents. However, the job to create and publish docker image needs to be run directly from the Jenkins server as thats where you have configured docker client to run. In order to support it, you would have to refactor the worker/Jenkinsfile to support per stage agents. pipeline{ agent none stages{ stage('build'){ agent{ docker{ image 'maven:3.6.1-jdk-8-slim' args '-v $HOME/.m2:/root/.m2' } } steps{ echo 'building worker app' dir('worker'){ sh 'mvn compile' } } } stage('test'){ agent{ docker{ image 'maven:3.6.1-jdk-8-slim' args '-v $HOME/.m2:/root/.m2' } } steps{ echo 'running unit tests on worker app' dir('worker'){ sh 'mvn clean test' } } } stage('package'){ agent{ docker{ image 'maven:3.6.1-jdk-8-slim' args '-v $HOME/.m2:/root/.m2' } } steps{ echo 'packaging worker app into a jarfile' dir('worker'){ sh 'mvn package -DskipTests' archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true } } } stage('docker-package'){ agent any steps{ echo 'Packaging worker app with docker' script{ docker.withRegistry('https://index.docker.io/v1/', 'dockerlogin') { def workerImage = docker.build(\"initcron/worker:v${env.BUILD_ID}\", \"./worker\") workerImage.push() workerImage.push(\"latest\") } } } } } post{ always{ echo 'the job is complete' } } }","title":"Lab 6 - Packaging Applications with Docker"},{"location":"dockerfile/#packaging-with-docker","text":"In addition to helping the process of building and testing software, docker could also provide a standard packaging format i.e. docker images. Along with this packaging format, comes the distribution mechanism i.e. docker image registries. In this lab you are going to learn, about Docker\u2019s standard imaging format How to test build docker images manually Learn how to write Dockerfiles understand the automated, iterative docker image process add docker packaging stage to the jenkins pipeline create per stage agent configurations in Jenkinsfile","title":"Packaging with Docker"},{"location":"dockerfile/#registering-with-the-dockerhub","text":"Since you are going to start working with the registry, build and push images to it later, its essential to have your own account on the registry. For the purpose of this tutorial, you are going to use the hosted registry i.e. Dockerhub. Steps to create Dockerhub account","title":"Registering with the DockerHub"},{"location":"dockerfile/#step-1","text":"Visit the following link and sign up with your email id https://hub.docker.com/","title":"Step 1:"},{"location":"dockerfile/#step-2","text":"Check your email inbox and check the activation email sent by docker team","title":"Step 2:"},{"location":"dockerfile/#step-3","text":"After clicking on the activation link, you will be redirected to a log in page. Enter your credentials and log in You will be launched to Dockerhub main page. Now the registration process is complete and you have account in Dockerhub!","title":"Step 3:"},{"location":"dockerfile/#lab-building-docker-images-a-manual-approach","text":"Before you start building automated images, you are going to create a docker image by hand. you have already used the pre built image from the registry in the last session. In this sub section, you are going to create an image with worker application installed. Since worker is a java based application, and needs maven to build it, you will base our work on existing official image for maven . Clone Repository for Java worker app git clone https://github.com/schoolofdevops/example-voting-app.git Launch an intermediate container to install worker app Create a Container with schoolofdevops/voteapp-mvn:v1 image docker run -idt --name build maven:3.6.1-jdk-8-slim sh Copy over the Source Code cd example-voting-app/worker docker container cp . build:/app Connect to container to compile and package the code docker exec -it build sh mvn package Verify jarfile has been built ls target/ java -jar target/worker-jar-with-dependencies.jar [sample output] /app # java -jar target/worker-jar-with-dependencies.jar Waiting for redis Waiting for redis Waiting for redis Waiting for redis Waiting for redis Waiting for redis ^c [use ^c to exit] The above is the expected output. The worker app keeps waiting for redis and then later db in a loop. Move the artifact, remove source code mv target/worker-jar-with-dependencies.jar /run/worker.jar rm -rf /app/* exit Commit container to an image Exit from the container shell Note container ID Commit the container into a image as, docker container commit build <docker hub user id >/worker:v1 Test before pushing by launching container with the packaged app docker run --rm -it <docker hub user id >/worker:v1 java -jar /run/worker.jar Push Image to registry Before you push the image, you need to be logged in to the registry, with the docker hub id created earlier. Login using the following command, docker login To push the image, first list it, docker image ls [Sample Output] REPOSITORY TAG IMAGE ID CREATED SIZE initcron/worker v2 90cbeb6539df 18 minutes ago 194MB initcron/worker v1 c0199f782489 34 minutes ago 189MB To push the image, docker push <dockrhub user id>/worker:v1","title":"Lab: Building Docker Images - A manual approach"},{"location":"dockerfile/#lab-building-images-with-dockerfile","text":"Now, lets build the same image, this time with Dockerfile. To do this, create a file by name Dockerfile in the root of the source code. file: example-voting-app/worker/Dockerfile FROM maven:3.6.1-jdk-8-slim WORKDIR /app COPY . . RUN mvn package && \\ mv target/worker-jar-with-dependencies.jar /run/worker.jar && \\ rm -rf /app/* CMD java -jar /run/worker.jar Lets now build the image cd example-voting-app/worker docker image build -t <dockrhub user id>/worker:v2 . docker image ls Try building again, docker image build -t <dockrhub user id>/worker:v2 . This time, it does not build everything, but uses cache. Testing the image docker container run --rm -it <dockrhub user id>/worker:v2 Tag the image as latest, docker image tag <dockrhub user id>/worker:v2 <dockrhub user id>/worker:latest docker image ls Finally, publish it to the registry, docker image push <dockrhub user id>/worker:latest docker image push <dockrhub user id>/worker","title":"Lab: Building Images with Dockerfile"},{"location":"dockerfile/#adding-docker-build-stage-to-jenkinsfile","text":"Add username/password type credential to Jenkins with name dockerlogin . Do do so, browse to Jenkins -> Credentials -> Jenkins -> Global Credentials -> Add Credentials -> Username and password . Ensure you add the dockerhub login and password with id as dockerlogin . Refactor the Jenkinsfile for worker app by adding the following stage file: worker/Jenkinsfile stage('docker-package'){ agent any steps{ echo 'Packaging worker app with docker' script{ docker.withRegistry('https://index.docker.io/v1/', 'dockerlogin') { def workerImage = docker.build(\"xxxx/worker:v${env.BUILD_ID}\", \"./worker\") workerImage.push() workerImage.push(\"latest\") } } } } You have configured the pipelines to run with docker agents. However, the job to create and publish docker image needs to be run directly from the Jenkins server as thats where you have configured docker client to run. In order to support it, you would have to refactor the worker/Jenkinsfile to support per stage agents. pipeline{ agent none stages{ stage('build'){ agent{ docker{ image 'maven:3.6.1-jdk-8-slim' args '-v $HOME/.m2:/root/.m2' } } steps{ echo 'building worker app' dir('worker'){ sh 'mvn compile' } } } stage('test'){ agent{ docker{ image 'maven:3.6.1-jdk-8-slim' args '-v $HOME/.m2:/root/.m2' } } steps{ echo 'running unit tests on worker app' dir('worker'){ sh 'mvn clean test' } } } stage('package'){ agent{ docker{ image 'maven:3.6.1-jdk-8-slim' args '-v $HOME/.m2:/root/.m2' } } steps{ echo 'packaging worker app into a jarfile' dir('worker'){ sh 'mvn package -DskipTests' archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true } } } stage('docker-package'){ agent any steps{ echo 'Packaging worker app with docker' script{ docker.withRegistry('https://index.docker.io/v1/', 'dockerlogin') { def workerImage = docker.build(\"initcron/worker:v${env.BUILD_ID}\", \"./worker\") workerImage.push() workerImage.push(\"latest\") } } } } } post{ always{ echo 'the job is complete' } } }","title":"Adding docker build stage to Jenkinsfile"},{"location":"dockerintro/","text":"Lab: Getting started with docker In this lab, you will learn How to launch containers with docker Common options used with docker container run command Run web applications and access those with port mapping and Learn how to manage container lifecycle and to debug those. Validating the setup Begin by checking the version of docker installed with, docker version you could further validate r by running a smoke test as, docker run hello-world This should launch a container successfully and show you hello world message. This smoke test validates the following, you have docker client installed docker daemon is up and running docker client is been correctly configured and authorized to talk to docker daemon you have non blocking internet connectivity you are able to pull an image from docker registry and run a container with it Launching your first container Before you begin launching your first container, open a new terminal and run the following command to analyze the events on the docker daemon side. docker system events When you launch the above command, you may not see any output. Keep that window open, and it would start streaming events as you proceed to use docker cli further. Now launch your first container with the following command, docker container run centos ps Where, docker is the command line client container run is the command to launch a container. You could alternately use just run command here centos is the image ps is the actual command which is run inside this container. Next go ahead and try creating a few more containers with the same imafge but with different commands as, docker container run centos uptime docker container run centos uname -a docker container run centos free you could check the events in the window where you have started running docker system events command earlier. It shows whats happening on docker daemon side. Listing Containers you can check your last run container using following commands, docker ps -l docker ps -n 2 docker ps -a where * -l : last run container * -n xx : last xx number of containers * -a : all containers (even if they are in stopped state ) Learning about images Containers are launched using images, which are pulled from registry. Observe following command, docker container run centos ps Here the image name is centos which can actually expanded to registry.docker.io/docker/centos:latest where following are the fields, registry: registry.docker.io namespace: docker repo: centos tag: latest You could use following commands to list your images from your local machine and pull the image from docker-hub. You could even examine the layers of an image with history command. docker image ls docker image pull nginx docker image history nginx Default run options You have learnt how to launch a container. However, its ephemeral, and exits immediately after running the command. To make the container persist, and in order to be able to interact with it, lets try adding a couple of new options. docker run -it centos bash where, * -i : interactive. provides standard in to the process running inside the container * -t : provides a pseudo terminal in order to interact You could further add --rm options to ensure the container is deleted when stopped. docker run --rm -it alpine sh Another useful and important option is -d , which will launch the process in a contained environment, and detach from it. This allows the container to keep running in the background. docker container run -idt --name redis redis:alpine Launching and connecting to Web Applications So far, you have launched a few simple containers, with one off commands. Its time to now learn how to launch a web application, and learn how to connect to it. You could launch a container with nginx web server as follows. Observe the new -p option. docker container run -idt -p 8080:80 nginx where, -p allows you to define a port mapping 8080 is host side port 80 is the container side port, the one on which application is listening Once you configure the port mapping, access that application on your browser by visiting http://IPADDRESS:8080 replace IPADDRESS with the *actual IP* in case your docker host is remote, or with *localhost* if using Docker Desktop. With the command above using -p option you explitly defined the host side port. You could also have docker pick the port automatically with -P option. docker container run -idt -P nginx where host port is automatically chosen and incremented starting with 32768 container port is automatically read from the image As usual you could use docker ps commands to observe the port mapping. Troubleshooting Containers To debug issues with the containers, which are nothing but processes running in an isolated environment, following could be two important tasks , checking process logs being able to establish a connecting inside container (simiar to ssh) You would learn about both in this sub section. To start examining logs find your container id or container name using docker ps You could use the following command to find out logs for a container whose name is redis docker logs redis You have an option of replacing redis name with the actual container id ( the first column in the output of docker ps command ). you can follow the logs using -f option and docker exec allows you to run a command inside a container. docker logs -f redis exec command allows you connect to the container and launch a shell inside it, similar to a ssh connection. It also allows running one off commands. docker exec redis ps docker exec -it redis sh With logs and exec commands which you should be able to get started with essential debugging. Summary You learnt about the basics of container operations. This foundation would help you through out the course as we plan to use docker extensively as part of the Continuous Integration and later with Continuous Delivery. Exercises With the knowledge that you have gained so far, you have been tasked with setting up the following two apps with docker Nextcloud Portainer Try launching it on your own before you proceed with the solutions given here . Stop, remove and cleanup Here you will learn how to stop, remove and cleanup the containers which you have created. Find your container id and stop the container before you are going to remove and you can pause and unpause the container as well. docker ps docker stop redis docker stop b584 84e6 e4da where ac69 b584 84e6 e4da are container ids these could vary on your system. Use the ones you see when you run docker ps you can start a container thats is in stopped state with, docker start redis To remove a container(destructive process) that is been stopped use, docker stop redis docker rm redis If the container is in running state, it can not be stopped unless a force optin is used. docker container run -idtP --name web nginx docker rm web docker rm -f web Images are independent of containers which are its run time instance. You could further remove the images using commands such as, docker image rm 4206 docker image rm 4f1 4d9 4c1 9f3 docker image prune where, 4206 4f1 4d9 4c1 9f3 are the beginning characters of the image ids on my host. You could get all your docker system information by using docker system info .","title":"Lab 1 - Docker for CI/CD"},{"location":"dockerintro/#lab-getting-started-with-docker","text":"In this lab, you will learn How to launch containers with docker Common options used with docker container run command Run web applications and access those with port mapping and Learn how to manage container lifecycle and to debug those.","title":"Lab: Getting started with docker"},{"location":"dockerintro/#validating-the-setup","text":"Begin by checking the version of docker installed with, docker version you could further validate r by running a smoke test as, docker run hello-world This should launch a container successfully and show you hello world message. This smoke test validates the following, you have docker client installed docker daemon is up and running docker client is been correctly configured and authorized to talk to docker daemon you have non blocking internet connectivity you are able to pull an image from docker registry and run a container with it","title":"Validating the setup"},{"location":"dockerintro/#launching-your-first-container","text":"Before you begin launching your first container, open a new terminal and run the following command to analyze the events on the docker daemon side. docker system events When you launch the above command, you may not see any output. Keep that window open, and it would start streaming events as you proceed to use docker cli further. Now launch your first container with the following command, docker container run centos ps Where, docker is the command line client container run is the command to launch a container. You could alternately use just run command here centos is the image ps is the actual command which is run inside this container. Next go ahead and try creating a few more containers with the same imafge but with different commands as, docker container run centos uptime docker container run centos uname -a docker container run centos free you could check the events in the window where you have started running docker system events command earlier. It shows whats happening on docker daemon side.","title":"Launching your first container"},{"location":"dockerintro/#listing-containers","text":"you can check your last run container using following commands, docker ps -l docker ps -n 2 docker ps -a where * -l : last run container * -n xx : last xx number of containers * -a : all containers (even if they are in stopped state )","title":"Listing Containers"},{"location":"dockerintro/#learning-about-images","text":"Containers are launched using images, which are pulled from registry. Observe following command, docker container run centos ps Here the image name is centos which can actually expanded to registry.docker.io/docker/centos:latest where following are the fields, registry: registry.docker.io namespace: docker repo: centos tag: latest You could use following commands to list your images from your local machine and pull the image from docker-hub. You could even examine the layers of an image with history command. docker image ls docker image pull nginx docker image history nginx","title":"Learning about images"},{"location":"dockerintro/#default-run-options","text":"You have learnt how to launch a container. However, its ephemeral, and exits immediately after running the command. To make the container persist, and in order to be able to interact with it, lets try adding a couple of new options. docker run -it centos bash where, * -i : interactive. provides standard in to the process running inside the container * -t : provides a pseudo terminal in order to interact You could further add --rm options to ensure the container is deleted when stopped. docker run --rm -it alpine sh Another useful and important option is -d , which will launch the process in a contained environment, and detach from it. This allows the container to keep running in the background. docker container run -idt --name redis redis:alpine","title":"Default run options"},{"location":"dockerintro/#launching-and-connecting-to-web-applications","text":"So far, you have launched a few simple containers, with one off commands. Its time to now learn how to launch a web application, and learn how to connect to it. You could launch a container with nginx web server as follows. Observe the new -p option. docker container run -idt -p 8080:80 nginx where, -p allows you to define a port mapping 8080 is host side port 80 is the container side port, the one on which application is listening Once you configure the port mapping, access that application on your browser by visiting http://IPADDRESS:8080 replace IPADDRESS with the *actual IP* in case your docker host is remote, or with *localhost* if using Docker Desktop. With the command above using -p option you explitly defined the host side port. You could also have docker pick the port automatically with -P option. docker container run -idt -P nginx where host port is automatically chosen and incremented starting with 32768 container port is automatically read from the image As usual you could use docker ps commands to observe the port mapping.","title":"Launching and connecting to Web Applications"},{"location":"dockerintro/#troubleshooting-containers","text":"To debug issues with the containers, which are nothing but processes running in an isolated environment, following could be two important tasks , checking process logs being able to establish a connecting inside container (simiar to ssh) You would learn about both in this sub section. To start examining logs find your container id or container name using docker ps You could use the following command to find out logs for a container whose name is redis docker logs redis You have an option of replacing redis name with the actual container id ( the first column in the output of docker ps command ). you can follow the logs using -f option and docker exec allows you to run a command inside a container. docker logs -f redis exec command allows you connect to the container and launch a shell inside it, similar to a ssh connection. It also allows running one off commands. docker exec redis ps docker exec -it redis sh With logs and exec commands which you should be able to get started with essential debugging.","title":"Troubleshooting Containers"},{"location":"dockerintro/#summary","text":"You learnt about the basics of container operations. This foundation would help you through out the course as we plan to use docker extensively as part of the Continuous Integration and later with Continuous Delivery.","title":"Summary"},{"location":"dockerintro/#exercises","text":"With the knowledge that you have gained so far, you have been tasked with setting up the following two apps with docker Nextcloud Portainer Try launching it on your own before you proceed with the solutions given here .","title":"Exercises"},{"location":"dockerintro/#stop-remove-and-cleanup","text":"Here you will learn how to stop, remove and cleanup the containers which you have created. Find your container id and stop the container before you are going to remove and you can pause and unpause the container as well. docker ps docker stop redis docker stop b584 84e6 e4da where ac69 b584 84e6 e4da are container ids these could vary on your system. Use the ones you see when you run docker ps you can start a container thats is in stopped state with, docker start redis To remove a container(destructive process) that is been stopped use, docker stop redis docker rm redis If the container is in running state, it can not be stopped unless a force optin is used. docker container run -idtP --name web nginx docker rm web docker rm -f web Images are independent of containers which are its run time instance. You could further remove the images using commands such as, docker image rm 4206 docker image rm 4f1 4d9 4c1 9f3 docker image prune where, 4206 4f1 4d9 4c1 9f3 are the beginning characters of the image ids on my host. You could get all your docker system information by using docker system info .","title":"Stop, remove and cleanup"},{"location":"dockerjenkins/","text":"Using docker with Jenkins Pipelines Objectives: You will learn how to prepare Jenkins environment to build with a docker agent Refactor Jenkinsfile with docker based agents Build and test nodejs, maven and python applications with docker Steps: Read : Using Docker with Pipeline Install docker inside jenkins container Restart Jenkins Container with Docker Refactor the Jenkinsfile for worker app using the following reference Test building with Docker Agent Create a test pipeline to run a job with docker agent Create docker-pipe-01 pipeline job in your jenkins. On the configuration page, add the following test code in jenkins pipeline script, save the configuration and build it. pipeline { agent { docker { image 'node:7-alpine' } } stages { stage('Test') { steps { sh 'node --version' } } } } Run the job, and check if that worked? If not, proceed with the next section to setup docker. Install Docker inside Jenkins Container Exec into jenkins container as root, docker exec -it -u root jenkins bash Run the following set of commands to install docker client and prepare Jenkins to launch containers from, apt-get update apt-get install -yq \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg2 \\ software-properties-common curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add - add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/debian \\ $(lsb_release -cs) \\ stable\" apt-get update apt-get install -yq docker-ce docker-ce-cli containerd.io usermod -a -G docker jenkins chown 777 /var/run/docker.sock curl -L \"https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose Finally, check if docker client is working and exit from the container. docker ps exit Restart jenkins containers so that it takes effect with the new configurations, docker restart jenkins Exec into jenkins container again, this time as jeknins user and validate, docker exec -it jenkins bash docker ps If you see the list of containers, docker client is been installed and configured ok. file: worker/Jenkinsfile pipeline{ agent{ docker{ image 'maven:3.6.1-jdk-8-slim' args '-v $HOME/.m2:/root/.m2' } } stages{ stage('build'){ steps{ echo 'building worker app' dir('worker'){ sh 'mvn compile' } } } stage('test'){ steps{ echo 'running unit tests on worker app' dir('worker'){ sh 'mvn clean test' } } } stage('package'){ steps{ echo 'packaging worker app into a jarfile' dir('worker'){ sh 'mvn package -DskipTests' archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true } } } } post{ always{ echo 'the job is complete' } } } Exercise Refactor the result/Jenkinsfile for nodeJS app Create a Jenkinsfile and a multi branch pipeline for vote python app","title":"Lab 5 - Using Docker to Simplify Jenkins Pipeline"},{"location":"dockerjenkins/#using-docker-with-jenkins-pipelines","text":"Objectives: You will learn how to prepare Jenkins environment to build with a docker agent Refactor Jenkinsfile with docker based agents Build and test nodejs, maven and python applications with docker Steps: Read : Using Docker with Pipeline Install docker inside jenkins container Restart Jenkins Container with Docker Refactor the Jenkinsfile for worker app using the following reference","title":"Using docker with Jenkins Pipelines"},{"location":"dockerjenkins/#test-building-with-docker-agent","text":"Create a test pipeline to run a job with docker agent Create docker-pipe-01 pipeline job in your jenkins. On the configuration page, add the following test code in jenkins pipeline script, save the configuration and build it. pipeline { agent { docker { image 'node:7-alpine' } } stages { stage('Test') { steps { sh 'node --version' } } } } Run the job, and check if that worked? If not, proceed with the next section to setup docker.","title":"Test building with Docker Agent"},{"location":"dockerjenkins/#install-docker-inside-jenkins-container","text":"Exec into jenkins container as root, docker exec -it -u root jenkins bash Run the following set of commands to install docker client and prepare Jenkins to launch containers from, apt-get update apt-get install -yq \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg2 \\ software-properties-common curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add - add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/debian \\ $(lsb_release -cs) \\ stable\" apt-get update apt-get install -yq docker-ce docker-ce-cli containerd.io usermod -a -G docker jenkins chown 777 /var/run/docker.sock curl -L \"https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose Finally, check if docker client is working and exit from the container. docker ps exit Restart jenkins containers so that it takes effect with the new configurations, docker restart jenkins Exec into jenkins container again, this time as jeknins user and validate, docker exec -it jenkins bash docker ps If you see the list of containers, docker client is been installed and configured ok. file: worker/Jenkinsfile pipeline{ agent{ docker{ image 'maven:3.6.1-jdk-8-slim' args '-v $HOME/.m2:/root/.m2' } } stages{ stage('build'){ steps{ echo 'building worker app' dir('worker'){ sh 'mvn compile' } } } stage('test'){ steps{ echo 'running unit tests on worker app' dir('worker'){ sh 'mvn clean test' } } } stage('package'){ steps{ echo 'packaging worker app into a jarfile' dir('worker'){ sh 'mvn package -DskipTests' archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true } } } } post{ always{ echo 'the job is complete' } } }","title":"Install Docker inside Jenkins Container"},{"location":"dockerjenkins/#exercise","text":"Refactor the result/Jenkinsfile for nodeJS app Create a Jenkinsfile and a multi branch pipeline for vote python app","title":"Exercise"},{"location":"git/","text":"Revision Control with Git In this lab, you will learn How to configure a git client, create and work with repositories basics of revision control operations branching and merging working with remotes resolving conflicts ( and also ) leveraging docker for local development Configuring git client Before you are start revision control, you need to configure git.There are three different places you can configure git, that are explained here. Git configs Type Scope Config Path LOCAL Repo .git/config GLOBAL User /home/user/.gitconfig SYSTEM System /etc/gitconfig You would create configurations with user scope, valid for all repositories the current user creates. git config --global user.name \"username\" git config --global user.email \"user@gmail.com\" git config -l cat ~/.gitconfig You could also create additional configurations e.g. editor git config --global core.editor vim git config -l git config -e --global Creating a sample application Here you will create a simple hello-world application using java based spring boot framework.To create the application visit startspringboot . Once you visit this page, change your artifact name and description. Click Generate! to download your application. After downloading the application code, move that zip file to your local working directory and unzip that application. you will use this application for revision control operations and writing simple web application. unzip hellocd.zip Basics of revision control Now that you have a hellocd application created and downloaded, you could use that to learn revision control operations. You could begin by initializing the repo cd hellocd git init . git status Once you check git status it will show all the current files as untracked. You need to add these files so that git starts tacking it. You could use the following commands to start tracking the files in hellocd project with git. git add pom.xml git commit git status git add src git add * git commit mvnw git commit -am \"adding files created with spring boot generator\" git log Three trees of Git Previously you added and committed all files using git commands. Lets learn what happened when you did that by understanding the three trees of git. You began by tracking the files in working directory then added those to the staging area and then started tracking with git by adding those to commit tree. Following image should explain this process git logs will shows you commit history and git status show you new file or untracked file in your directory. you just add one more file in your working directory README.md and then check your git status after that commit that using reset. git add README.md git status git reset README.md git add README.md git commit -am \"adding README\" In this you have added and commited the files one by one, that flow chat is given following and this is the current state of your repository. Using docker in development After creating a java project based on maven, you may wish to build it. Beginning with compilation followed by testing, it could then be deployed into an environment. To do this, you would need a build environment. Instead of setting up and then managing a build environment with maven, java etc. you could leverage docker's important feature here, disposability. Use the following command to run the container. Note: Before you run this command, you need to find out the absolute path for the directory where you are running this from (e.g. hellocd). You could dind it by running pwd command. docker container run --rm -it -v /absolute/path/to/ci-cd/hellocd:/app maven:alpine sh Running above command, should get you a, disposable container environment with docker created with image maven:alpine that should have the build tools including maven, java etc. and exiting this container would delete it as we are using --rm options while inside the container, you could attempt to build the project as, mvn spring-boot:run -f app/pom.xml And run it with, mvn spring-boot:run -f app/pom.xml You could see your libraries are stored in /root/.m2/ directory. you can reduce the time to download libraries by creating a volume which can then be mounted at this path. docker volume create m2 docker container run --rm -it -v m2:/root/.m2 -v /Users/gouravshah/learn/ci-cd/hellocd:app maven:alpine mvn spring-boot:run -f /app/pom.xml When you run docker container run again, you should notice the build being faster due to maven packaes being cached with the newly mounted volume. Getting started with Branching and Merging You could create branch using git branch command and switch it to that branch using git checkout . Default branch is master, whenever you need to work on other branch, you could use git checkout . git branch --list git log git branch webapp git branch --list git branch checkout webapp Instead of using a two step process, You could create a branch and switch to it with, git checkout -b webapp You can delete your branch using git branch -d . Before deleteing the branch you should switch to another. git checkout master git branch -d webapp Adding a new feature by branching out Now you are going to add a new features to your application, source code changes visit lfs261devops-repo and goto hellocd directory copy HellocdApplication.java.v1 code and replace the HellocdApplication.java in your src/main/java/com/example/hellocd directory . copy pom.xml.snippet1 from above url and add it to pom.xml file under dependency section. Now you can check your git status, the result will be those files you have changed are in untracked. You can check changes by using git diff and you could commit after git add else directly commit by using git commit -a with the editor. git add pom.xml git commit -a git status Now you can see the changes are in new branch, Master still does not ave any of those incorporated yet. This is the safer way of bringing your code to master. With the next sub section, you would learn how to bring these changes in to the master. Merging with commit history Previously you have made some changes and committed to a new branch webapp . Its now time to test the application. Again run the same spring-boot container command with port mapped to 8080 on host docker container run --rm -it -v m2:/root/.m2 -v /Users/gouravshah/learn/ci-cd/hellocd:app -p 8080:8080 maven:alpine mvn spring-boot:run -f /app/pom.xml Once the container is running you can visit the application on http://IPADDRESS:8080 , but you will get some error due to some snippet missing on HellocdApplication.java . To fix this issue you could copy HellocdApplication.java.v2 from the devops-repo and replace entirely. After replacing the snippet run the following commands to commit. git diff git commit -am \"added missing annotations\" Again run your spring-boot container and visit localhost:8080 . You should now see hello world on your browser. You could change to hello Continuous Delivery instead of hello world in HellocdApplication.java and commit that, again run your container. Now you can see hello Continuous Delivery in the browser. Now that the feature is added, its time to incorporate these changes in to master by using git merge . Before you do so, make sure you switch to the master branch first. git checkout master git merge webapp git log If you don't want to continue new feature branch then delete that by using git branch -d and total branch workflow is given following for your reference. git branch -d webapp Working with Remotes You could collaborate and works with different branches, users or central repository by using remotes.Here your central repository is github, actually you work with is as the remote and clone from github or create the code, initialize and push the code into the github repository. Before start you need to create account in github, visit the github link to create your account. while create account use free account option. Once you create an account, create a new hellocd public repository. You have two ways to work with repository, first is like you could use initialized repository or second one is clone the repository form github and make changes and push to your repository. Here you are already initialized a repository, now you need to add newly created repository as a origin by using following command and push your application to that origin master, git remote add origin https://github.com/initcron/hellocd.git git remote show git remote show origin git push origin master Once you push to origin master, you can see your code in the repository with commit what you have changed. Resolving conflicts Just like in real life, when you are collaborating with others, conflicts may happen. Git provide you various options to resolve those. Add sever.port=80 in src/main/resource/application.properties while you are on the master branch, commit and push. git diff git commit -am \"added server port 80\" git push origin master Creating a Conflict To resolve a conflict, first we would have to create one, to the least simulate it. TO do that, you would be creating two branches, and updating the same file with different content from those. Following sequence of commands would help you do that. You have an option to work in pairs here. The commands are differenciated with user1 and user2 . Make sure you are working with the same repository in case of a pair. If you can not come up with a pair, go ahead and run both blocks of commands from the same workspace. user1: use the following code git checkout -b user1 ``` set value of server.port to 8080 in `src/main/resource/application.properties` ``` git diff git commit -am \"this should run on port 8080\" git push origin user1 user2: use the following git checkout -b user2 set value of server.port to 8081 in src/main/resource/application.properties git diff git commit -am \"this should run on port 8081\" git push origin user2 Once you do the above, switch to the master branch and try to merge the branches you just updated, simultaneously. user1: git checkout master git pull origin user2 git log git push origin master user2: git checkout master git pull origin user1 git log git push origin master You should get a conflict here. Use git log to check the details. Manually resolving a Conflict You could resolve a conflict manually by editing the file in conflict. In this example, You could pick one value for server.port and keep that line in the file. Remove everything else including the lines staring with <<<<<<<< and >>>>>>>>>. Once you do so, add it back and merge as, git add src/main/resource/application.properties git commit -a git push origin master Validate by examining the commit history. git log Once you complete this, delete your user1 & user2 branches by using following commands, git branch -d user1 git branch -d user2 git push origin --delete user1 git push origin --delete user2 Learning to Undo Its common to add changes to the commit history and later wish you could have taken those back. At times, there are silly mistakes, or bugs you detect in your feature branches, that do not need to reflect in the commit history. There are often times, when you may wish to unstage s file. Git offers reset command with its options to achieve this. Lets add a change that we would undo later. git checkout -b config git branch Update src/main/resource/application.properties with server.port=9000 git status git add src/main/resource/application.properties git status The file is now been staged. To unstage the same, git reset src/main/resource/application.properties git status git diff git commit -am \"changed port to 9000\" git log git push origin config You have not only added it to a commit history but also pushed the change to the remote. You just realised that port configured 9000 should just be 8080 . Now you are wondering how to bring that change back. Git reset can come in handy here as well, however, this time since its been added to commit history, you would have to use a special option to undo this time. Try using the following command, git reset HEAD~1 This should revert the last commit and point the HEAD (tip of the git repo) to the previous commit You could use HEAD~2, HEAD~3 to shift the HEAD back by two/three commits respectively You could optionally use the commit id to shift HEAD to a specific commit What you did above was a soft reset. Meaning, the undo was done for the commit history only. You would still see the files in the staging area, and current working tree being unchanged. You could undo it all the way ( this is a destructive process) by doing a hard reset as, git reset --hard HEAD~1 Once you reset,if you try to push with the changes to remote, it should give you a error. To undo changes to remote, use force option. git push origin config -f Revert vs Reset Reset is useful while working on feature/personal branches. However, when you have a collaborative workflow, with common branches such as trunk/mainline/master, resetting changes on common branches could leave everyone else confused and in inconsistent state. THis is because reset wipes out the commits to undo changes. A cleaner solution in such cases is using git revert instead, which undoes the changes, however by adding a new commit, which is then part of the commit history, leaving everyone in sync. To learn how revert works, lets first update a file and commit it. You could config2 branch and file and commit the changes in feature branch, bring those changes to master branch using following commands, git checkout -b config2 Update src/main/resource/application.properties with service.port=7000 git diff git commit -am \"run on port 7000\" git push origin config2 git checkout master git pull origin config2 git push origin master Now that you have incorporated these changes to the master branch, its time to revert. git log git revert HEAD (or) git revert 5080dcc9d13ac920b5867891166a where, 5080dcc9d13ac920b5867891166a is the previous commit id that you would want to revert. Once you revert, you need sync changes in master branch with remote by using following command. git log git push origin master Once sync the changes, it will show the changes to your co-developer and delete your config2 branch after git revert. Go ahead and delete the branch after you are done with, git branch delete config2 git push origin :config2 Exercise: Working with github You have been tasked to create a Let you create new repository skills journal ,add a description and init with README file with the license for your public repository. Once you create repository , clone the repository locally by using following command and add your skills in a file, push to your origin. git clone https://github.com/mohaninit/skills-journal.git git add skills.md git commit -am \"added skills\" git remote show git remote show origin git push origin master You could create more files, commit it and push it in your repository.","title":"Lab 2 - Revision Control with Git"},{"location":"git/#revision-control-with-git","text":"In this lab, you will learn How to configure a git client, create and work with repositories basics of revision control operations branching and merging working with remotes resolving conflicts ( and also ) leveraging docker for local development","title":"Revision Control with Git"},{"location":"git/#configuring-git-client","text":"Before you are start revision control, you need to configure git.There are three different places you can configure git, that are explained here. Git configs Type Scope Config Path LOCAL Repo .git/config GLOBAL User /home/user/.gitconfig SYSTEM System /etc/gitconfig You would create configurations with user scope, valid for all repositories the current user creates. git config --global user.name \"username\" git config --global user.email \"user@gmail.com\" git config -l cat ~/.gitconfig You could also create additional configurations e.g. editor git config --global core.editor vim git config -l git config -e --global","title":"Configuring git client"},{"location":"git/#creating-a-sample-application","text":"Here you will create a simple hello-world application using java based spring boot framework.To create the application visit startspringboot . Once you visit this page, change your artifact name and description. Click Generate! to download your application. After downloading the application code, move that zip file to your local working directory and unzip that application. you will use this application for revision control operations and writing simple web application. unzip hellocd.zip","title":"Creating a sample application"},{"location":"git/#basics-of-revision-control","text":"Now that you have a hellocd application created and downloaded, you could use that to learn revision control operations. You could begin by initializing the repo cd hellocd git init . git status Once you check git status it will show all the current files as untracked. You need to add these files so that git starts tacking it. You could use the following commands to start tracking the files in hellocd project with git. git add pom.xml git commit git status git add src git add * git commit mvnw git commit -am \"adding files created with spring boot generator\" git log","title":"Basics of revision control"},{"location":"git/#three-trees-of-git","text":"Previously you added and committed all files using git commands. Lets learn what happened when you did that by understanding the three trees of git. You began by tracking the files in working directory then added those to the staging area and then started tracking with git by adding those to commit tree. Following image should explain this process git logs will shows you commit history and git status show you new file or untracked file in your directory. you just add one more file in your working directory README.md and then check your git status after that commit that using reset. git add README.md git status git reset README.md git add README.md git commit -am \"adding README\" In this you have added and commited the files one by one, that flow chat is given following and this is the current state of your repository.","title":"Three trees of Git"},{"location":"git/#using-docker-in-development","text":"After creating a java project based on maven, you may wish to build it. Beginning with compilation followed by testing, it could then be deployed into an environment. To do this, you would need a build environment. Instead of setting up and then managing a build environment with maven, java etc. you could leverage docker's important feature here, disposability. Use the following command to run the container. Note: Before you run this command, you need to find out the absolute path for the directory where you are running this from (e.g. hellocd). You could dind it by running pwd command. docker container run --rm -it -v /absolute/path/to/ci-cd/hellocd:/app maven:alpine sh Running above command, should get you a, disposable container environment with docker created with image maven:alpine that should have the build tools including maven, java etc. and exiting this container would delete it as we are using --rm options while inside the container, you could attempt to build the project as, mvn spring-boot:run -f app/pom.xml And run it with, mvn spring-boot:run -f app/pom.xml You could see your libraries are stored in /root/.m2/ directory. you can reduce the time to download libraries by creating a volume which can then be mounted at this path. docker volume create m2 docker container run --rm -it -v m2:/root/.m2 -v /Users/gouravshah/learn/ci-cd/hellocd:app maven:alpine mvn spring-boot:run -f /app/pom.xml When you run docker container run again, you should notice the build being faster due to maven packaes being cached with the newly mounted volume.","title":"Using docker in development"},{"location":"git/#getting-started-with-branching-and-merging","text":"You could create branch using git branch command and switch it to that branch using git checkout . Default branch is master, whenever you need to work on other branch, you could use git checkout . git branch --list git log git branch webapp git branch --list git branch checkout webapp Instead of using a two step process, You could create a branch and switch to it with, git checkout -b webapp You can delete your branch using git branch -d . Before deleteing the branch you should switch to another. git checkout master git branch -d webapp","title":"Getting started with Branching and Merging"},{"location":"git/#adding-a-new-feature-by-branching-out","text":"Now you are going to add a new features to your application, source code changes visit lfs261devops-repo and goto hellocd directory copy HellocdApplication.java.v1 code and replace the HellocdApplication.java in your src/main/java/com/example/hellocd directory . copy pom.xml.snippet1 from above url and add it to pom.xml file under dependency section. Now you can check your git status, the result will be those files you have changed are in untracked. You can check changes by using git diff and you could commit after git add else directly commit by using git commit -a with the editor. git add pom.xml git commit -a git status Now you can see the changes are in new branch, Master still does not ave any of those incorporated yet. This is the safer way of bringing your code to master. With the next sub section, you would learn how to bring these changes in to the master.","title":"Adding a new feature by branching out"},{"location":"git/#merging-with-commit-history","text":"Previously you have made some changes and committed to a new branch webapp . Its now time to test the application. Again run the same spring-boot container command with port mapped to 8080 on host docker container run --rm -it -v m2:/root/.m2 -v /Users/gouravshah/learn/ci-cd/hellocd:app -p 8080:8080 maven:alpine mvn spring-boot:run -f /app/pom.xml Once the container is running you can visit the application on http://IPADDRESS:8080 , but you will get some error due to some snippet missing on HellocdApplication.java . To fix this issue you could copy HellocdApplication.java.v2 from the devops-repo and replace entirely. After replacing the snippet run the following commands to commit. git diff git commit -am \"added missing annotations\" Again run your spring-boot container and visit localhost:8080 . You should now see hello world on your browser. You could change to hello Continuous Delivery instead of hello world in HellocdApplication.java and commit that, again run your container. Now you can see hello Continuous Delivery in the browser. Now that the feature is added, its time to incorporate these changes in to master by using git merge . Before you do so, make sure you switch to the master branch first. git checkout master git merge webapp git log If you don't want to continue new feature branch then delete that by using git branch -d and total branch workflow is given following for your reference. git branch -d webapp","title":"Merging with commit history"},{"location":"git/#working-with-remotes","text":"You could collaborate and works with different branches, users or central repository by using remotes.Here your central repository is github, actually you work with is as the remote and clone from github or create the code, initialize and push the code into the github repository. Before start you need to create account in github, visit the github link to create your account. while create account use free account option. Once you create an account, create a new hellocd public repository. You have two ways to work with repository, first is like you could use initialized repository or second one is clone the repository form github and make changes and push to your repository. Here you are already initialized a repository, now you need to add newly created repository as a origin by using following command and push your application to that origin master, git remote add origin https://github.com/initcron/hellocd.git git remote show git remote show origin git push origin master Once you push to origin master, you can see your code in the repository with commit what you have changed.","title":"Working with Remotes"},{"location":"git/#resolving-conflicts","text":"Just like in real life, when you are collaborating with others, conflicts may happen. Git provide you various options to resolve those. Add sever.port=80 in src/main/resource/application.properties while you are on the master branch, commit and push. git diff git commit -am \"added server port 80\" git push origin master","title":"Resolving conflicts"},{"location":"git/#creating-a-conflict","text":"To resolve a conflict, first we would have to create one, to the least simulate it. TO do that, you would be creating two branches, and updating the same file with different content from those. Following sequence of commands would help you do that. You have an option to work in pairs here. The commands are differenciated with user1 and user2 . Make sure you are working with the same repository in case of a pair. If you can not come up with a pair, go ahead and run both blocks of commands from the same workspace. user1: use the following code git checkout -b user1 ``` set value of server.port to 8080 in `src/main/resource/application.properties` ``` git diff git commit -am \"this should run on port 8080\" git push origin user1 user2: use the following git checkout -b user2 set value of server.port to 8081 in src/main/resource/application.properties git diff git commit -am \"this should run on port 8081\" git push origin user2 Once you do the above, switch to the master branch and try to merge the branches you just updated, simultaneously. user1: git checkout master git pull origin user2 git log git push origin master user2: git checkout master git pull origin user1 git log git push origin master You should get a conflict here. Use git log to check the details.","title":"Creating a Conflict"},{"location":"git/#manually-resolving-a-conflict","text":"You could resolve a conflict manually by editing the file in conflict. In this example, You could pick one value for server.port and keep that line in the file. Remove everything else including the lines staring with <<<<<<<< and >>>>>>>>>. Once you do so, add it back and merge as, git add src/main/resource/application.properties git commit -a git push origin master Validate by examining the commit history. git log Once you complete this, delete your user1 & user2 branches by using following commands, git branch -d user1 git branch -d user2 git push origin --delete user1 git push origin --delete user2","title":"Manually resolving a Conflict"},{"location":"git/#learning-to-undo","text":"Its common to add changes to the commit history and later wish you could have taken those back. At times, there are silly mistakes, or bugs you detect in your feature branches, that do not need to reflect in the commit history. There are often times, when you may wish to unstage s file. Git offers reset command with its options to achieve this. Lets add a change that we would undo later. git checkout -b config git branch Update src/main/resource/application.properties with server.port=9000 git status git add src/main/resource/application.properties git status The file is now been staged. To unstage the same, git reset src/main/resource/application.properties git status git diff git commit -am \"changed port to 9000\" git log git push origin config You have not only added it to a commit history but also pushed the change to the remote. You just realised that port configured 9000 should just be 8080 . Now you are wondering how to bring that change back. Git reset can come in handy here as well, however, this time since its been added to commit history, you would have to use a special option to undo this time. Try using the following command, git reset HEAD~1 This should revert the last commit and point the HEAD (tip of the git repo) to the previous commit You could use HEAD~2, HEAD~3 to shift the HEAD back by two/three commits respectively You could optionally use the commit id to shift HEAD to a specific commit What you did above was a soft reset. Meaning, the undo was done for the commit history only. You would still see the files in the staging area, and current working tree being unchanged. You could undo it all the way ( this is a destructive process) by doing a hard reset as, git reset --hard HEAD~1 Once you reset,if you try to push with the changes to remote, it should give you a error. To undo changes to remote, use force option. git push origin config -f","title":"Learning to Undo"},{"location":"git/#revert-vs-reset","text":"Reset is useful while working on feature/personal branches. However, when you have a collaborative workflow, with common branches such as trunk/mainline/master, resetting changes on common branches could leave everyone else confused and in inconsistent state. THis is because reset wipes out the commits to undo changes. A cleaner solution in such cases is using git revert instead, which undoes the changes, however by adding a new commit, which is then part of the commit history, leaving everyone in sync. To learn how revert works, lets first update a file and commit it. You could config2 branch and file and commit the changes in feature branch, bring those changes to master branch using following commands, git checkout -b config2 Update src/main/resource/application.properties with service.port=7000 git diff git commit -am \"run on port 7000\" git push origin config2 git checkout master git pull origin config2 git push origin master Now that you have incorporated these changes to the master branch, its time to revert. git log git revert HEAD (or) git revert 5080dcc9d13ac920b5867891166a where, 5080dcc9d13ac920b5867891166a is the previous commit id that you would want to revert. Once you revert, you need sync changes in master branch with remote by using following command. git log git push origin master Once sync the changes, it will show the changes to your co-developer and delete your config2 branch after git revert. Go ahead and delete the branch after you are done with, git branch delete config2 git push origin :config2","title":"Revert vs Reset"},{"location":"git/#exercise-working-with-github","text":"You have been tasked to create a Let you create new repository skills journal ,add a description and init with README file with the license for your public repository. Once you create repository , clone the repository locally by using following command and add your skills in a file, push to your origin. git clone https://github.com/mohaninit/skills-journal.git git add skills.md git commit -am \"added skills\" git remote show git remote show origin git push origin master You could create more files, commit it and push it in your repository.","title":"Exercise:  Working with github"},{"location":"jenkins/","text":"Setting up Continuous Integration with Jenkins Following are the learning objectives with this lab you will begin by setting up Jenkins using docker take a walkthrough of Jenkins web interface and essential configurations start creating freestyle and maven jobs integrate with tools such as nodeJS and maven integrate with GitHub and setup build triggers and. setup a pipelines which run automated builds and unit tests Setup Jenkins with Docker Here you are going learn, how to setup jenkins using docker. prerequisite for this is docker installation. You could run a jenkins container on your docker host by using official jenkins image with the version 2.178-Slim . Use following command to launch the jenkins container, docker container run -idt --name jenkins -P -p 8080:8080 -v jenkins_home:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock jenkins/jenkins:2.204-slim You could access jenkins UI by browsing to http://IPADDRESS:8080 To fetch the initialAdminPassword use the following command docker logs jenkins and paste it on the Jenkins UI to unlock. In the next step , choose install suggested plugins to configure the default plugins automatically. Once plugins are installed, you will create the admin user using the form presented. completing this process will get you to jenkins main page where you could get started creating jobs from. Creating first Jenkins Job After setting up jenkins, its now time to create your first jenkins job and run it. You could create jenkins job to build one of the applications with the instavote sample app you have learnt about. You need to create your version of this app by forking it. Visit example-voting-app on Github and fork the repository onto your git account. Once you forked the repository, goto jenkins dashboard and clickon create new Jobs . Now you are going to create a freestyle job with the name of job-01 and click ok to configure your job. You will get job configuration page where you could choose the following options. Steps: Goto job-01 cofiguration page, add description of your job. Under source code management choose git and provide your project repository url copied from github repo. Next select build tab and choose execute shell to run following commands ls -ltr sleep 10 once you fill in the build step, save the job configuration page. Goto your project page , choose build option to build your job. Once your build finished, click on your build and check build execute status. Every build you could see build status, it will store logs of your build. Observe the color coding in the build status. If your job is successful it will show as blue, if it fails you could see it turn red Configuring a maven build job You have already created a simple, freestyle project with name job-01 and tested it. Now is the time to build the worker application as part of the instavote project, which is a java application that uses maven as a build tool. You could follow the following steps to configure maven build job. Steps: Goto manage jenkins -> global tools configuration and under maven section, provide name as Maven 3.6.2 and select the maven version 3.6.2 , save those changes. Install Maven integration plugin. Goto Manage Jenkins => Manage Plugins => Available ,search for Maven Integration plugin and install it without restart. Create instavote folder for your project which serves as a namespace. Do so by creating a new job with type folder with name instavote Switch to instavote folder, create a new project and select Maven as the type of project. Name the job as worker-build Next goto source code management, provide your git repository url Go to build step and provide the goal and option as compile . At the build step, you would also need to provide the path to pom.xml, which in the worker subdirectory of the repo. e.g. worker/pom.xml as Save the job and build. Observe the job status, console output etc. Adding unit test and packaging jobs After creating the build job, its now time to add test and package jobs for the worker application. You need to create one more job on your same folder and name it as worker-test , while creating worker-test copy worker-build job. Follow following steps to complete the configuration. Steps In worker-test job , change your description as test worker java app . Source code management,repository is same . under build step, change the goals and option as clean test and remaining will be same, so save the job and build. Next job is worker-package , this will compile the application and then generate the jar file. Create a job on same folder with the name of worker-package , while creating job copy worker-test or worker- build job. Update the description as package worker java app, create jar and only change in the configuration is build step. In the build step for the package job, change the goal to package -DskipTests , save the changes and build. After build succesful, you could see the jar file created in the workspace. Example is given following , you can verify your workspace by using it. From the post build actions, choose archive artifacts and provide path **/target/*.jar to store the jar file. Save the changes and build the job. Once build succesful, check the project page to find out your artifacts right out there. Configuring Build Triggers You could use anything under build triggers for automatic build, but now you are going to use poll scm under build triggers. goto your worker-build job configuration page and choose poll SCM under build triggers. In that poll scm mention schedule for periodically polling the git repository. H/2 * * * * Once you made changes, save the job. goto your job page there you will find Git polling log , check your polling logs by using Git polling log. Now you are going to use Trigger builds remotely in build trigger. provide your authentication token randomly and save it. Use the following example to trigger the build using browser. You should get a trigger URL mentioned just below where you defined the token on Jenkins job configuration page. Generate your custom trigger URL similar to following http://localhost:8080/job/instavote/job/worker-build/build?token=yourauthenticationtoken If you paste this URL on the browser, since you are already authenticated, you should see the job launched automatically. You could also trigger the build using a command line interface or programtically from external code by providing the api token. To create the api token by browsing to jenkins -> people -> admin -> configure as shown in the following image. Copy the api token to generate a remote trigger URL similar to following, http://admin:TOKEN@localhost:8080/job/instavote/job/worker-build/build?token=yourauthenticationtoken Test trigger the build using a curl command or equivalent curl http://admin:yourapitoken@localhost:8080/job/instavote/job/worker-build/build?token=yourauthenticationtoken The above instructions demonstrate how to trigger builds remotely. Creating a Job pipeline Here you will learn, how to links the jobs by defining upstreams and downstreams. You would also go on to create a pipeline view using a plugin. Follow the following steps to setup upstream and downstream From woker-build job configuration page, scroll all the way to post build actions , this is where you could define the downstream job. Provide worker-test as the job to build and save. Now you are going to setup upstream for worker-package . goto worker-package configuration page. From build triggers , check the box for build after other projects are built Provide upstream project name as woker-test job this defines the upstream for worker-package. Once upstreams and downstreams are defined, run worker-build and it will automatically run worker-test & worker-package . Setup Pipeline View Now you are going to setup pipeline view for this build jobs, Begin by installing **Build Pipeline** plugin from manage jenkins page. From jenkins console, create a new view. Select type as pipeline view and provide name for it. From the configuration page, select the first job in the pipeline and select number of builds as 5, save it. Once you complete, you could see Build Pipeline of your job. Green is successful, red is failed and blue is to do, yellow is in progress. You have just completed creating a pipeline for a java project. Assignment - Create a pipeline for the Nodejs app Here you need to create pipeline for result application and use build tool as npm. Create two jobs, first by name result-build which will will run npm install and define the second job as downstream. result-test is the second job, which will run npm test as the command. These two should be triggered automatically via a PollSCM trigger scheduled to run every two minutes .","title":"Lab 3 - Setting up CI Pipeline with Jenkins"},{"location":"jenkins/#setting-up-continuous-integration-with-jenkins","text":"Following are the learning objectives with this lab you will begin by setting up Jenkins using docker take a walkthrough of Jenkins web interface and essential configurations start creating freestyle and maven jobs integrate with tools such as nodeJS and maven integrate with GitHub and setup build triggers and. setup a pipelines which run automated builds and unit tests","title":"Setting up Continuous Integration with Jenkins"},{"location":"jenkins/#setup-jenkins-with-docker","text":"Here you are going learn, how to setup jenkins using docker. prerequisite for this is docker installation. You could run a jenkins container on your docker host by using official jenkins image with the version 2.178-Slim . Use following command to launch the jenkins container, docker container run -idt --name jenkins -P -p 8080:8080 -v jenkins_home:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock jenkins/jenkins:2.204-slim You could access jenkins UI by browsing to http://IPADDRESS:8080 To fetch the initialAdminPassword use the following command docker logs jenkins and paste it on the Jenkins UI to unlock. In the next step , choose install suggested plugins to configure the default plugins automatically. Once plugins are installed, you will create the admin user using the form presented. completing this process will get you to jenkins main page where you could get started creating jobs from.","title":"Setup Jenkins with Docker"},{"location":"jenkins/#creating-first-jenkins-job","text":"After setting up jenkins, its now time to create your first jenkins job and run it. You could create jenkins job to build one of the applications with the instavote sample app you have learnt about. You need to create your version of this app by forking it. Visit example-voting-app on Github and fork the repository onto your git account. Once you forked the repository, goto jenkins dashboard and clickon create new Jobs . Now you are going to create a freestyle job with the name of job-01 and click ok to configure your job. You will get job configuration page where you could choose the following options. Steps: Goto job-01 cofiguration page, add description of your job. Under source code management choose git and provide your project repository url copied from github repo. Next select build tab and choose execute shell to run following commands ls -ltr sleep 10 once you fill in the build step, save the job configuration page. Goto your project page , choose build option to build your job. Once your build finished, click on your build and check build execute status. Every build you could see build status, it will store logs of your build. Observe the color coding in the build status. If your job is successful it will show as blue, if it fails you could see it turn red","title":"Creating first Jenkins Job"},{"location":"jenkins/#configuring-a-maven-build-job","text":"You have already created a simple, freestyle project with name job-01 and tested it. Now is the time to build the worker application as part of the instavote project, which is a java application that uses maven as a build tool. You could follow the following steps to configure maven build job. Steps: Goto manage jenkins -> global tools configuration and under maven section, provide name as Maven 3.6.2 and select the maven version 3.6.2 , save those changes. Install Maven integration plugin. Goto Manage Jenkins => Manage Plugins => Available ,search for Maven Integration plugin and install it without restart. Create instavote folder for your project which serves as a namespace. Do so by creating a new job with type folder with name instavote Switch to instavote folder, create a new project and select Maven as the type of project. Name the job as worker-build Next goto source code management, provide your git repository url Go to build step and provide the goal and option as compile . At the build step, you would also need to provide the path to pom.xml, which in the worker subdirectory of the repo. e.g. worker/pom.xml as Save the job and build. Observe the job status, console output etc.","title":"Configuring a maven build job"},{"location":"jenkins/#adding-unit-test-and-packaging-jobs","text":"After creating the build job, its now time to add test and package jobs for the worker application. You need to create one more job on your same folder and name it as worker-test , while creating worker-test copy worker-build job. Follow following steps to complete the configuration. Steps In worker-test job , change your description as test worker java app . Source code management,repository is same . under build step, change the goals and option as clean test and remaining will be same, so save the job and build. Next job is worker-package , this will compile the application and then generate the jar file. Create a job on same folder with the name of worker-package , while creating job copy worker-test or worker- build job. Update the description as package worker java app, create jar and only change in the configuration is build step. In the build step for the package job, change the goal to package -DskipTests , save the changes and build. After build succesful, you could see the jar file created in the workspace. Example is given following , you can verify your workspace by using it. From the post build actions, choose archive artifacts and provide path **/target/*.jar to store the jar file. Save the changes and build the job. Once build succesful, check the project page to find out your artifacts right out there.","title":"Adding unit test and packaging jobs"},{"location":"jenkins/#configuring-build-triggers","text":"You could use anything under build triggers for automatic build, but now you are going to use poll scm under build triggers. goto your worker-build job configuration page and choose poll SCM under build triggers. In that poll scm mention schedule for periodically polling the git repository. H/2 * * * * Once you made changes, save the job. goto your job page there you will find Git polling log , check your polling logs by using Git polling log. Now you are going to use Trigger builds remotely in build trigger. provide your authentication token randomly and save it. Use the following example to trigger the build using browser. You should get a trigger URL mentioned just below where you defined the token on Jenkins job configuration page. Generate your custom trigger URL similar to following http://localhost:8080/job/instavote/job/worker-build/build?token=yourauthenticationtoken If you paste this URL on the browser, since you are already authenticated, you should see the job launched automatically. You could also trigger the build using a command line interface or programtically from external code by providing the api token. To create the api token by browsing to jenkins -> people -> admin -> configure as shown in the following image. Copy the api token to generate a remote trigger URL similar to following, http://admin:TOKEN@localhost:8080/job/instavote/job/worker-build/build?token=yourauthenticationtoken Test trigger the build using a curl command or equivalent curl http://admin:yourapitoken@localhost:8080/job/instavote/job/worker-build/build?token=yourauthenticationtoken The above instructions demonstrate how to trigger builds remotely.","title":"Configuring Build Triggers"},{"location":"jenkins/#creating-a-job-pipeline","text":"Here you will learn, how to links the jobs by defining upstreams and downstreams. You would also go on to create a pipeline view using a plugin. Follow the following steps to setup upstream and downstream From woker-build job configuration page, scroll all the way to post build actions , this is where you could define the downstream job. Provide worker-test as the job to build and save. Now you are going to setup upstream for worker-package . goto worker-package configuration page. From build triggers , check the box for build after other projects are built Provide upstream project name as woker-test job this defines the upstream for worker-package. Once upstreams and downstreams are defined, run worker-build and it will automatically run worker-test & worker-package .","title":"Creating a Job pipeline"},{"location":"jenkins/#setup-pipeline-view","text":"Now you are going to setup pipeline view for this build jobs, Begin by installing **Build Pipeline** plugin from manage jenkins page. From jenkins console, create a new view. Select type as pipeline view and provide name for it. From the configuration page, select the first job in the pipeline and select number of builds as 5, save it. Once you complete, you could see Build Pipeline of your job. Green is successful, red is failed and blue is to do, yellow is in progress. You have just completed creating a pipeline for a java project.","title":"Setup Pipeline View"},{"location":"jenkins/#assignment-create-a-pipeline-for-the-nodejs-app","text":"Here you need to create pipeline for result application and use build tool as npm. Create two jobs, first by name result-build which will will run npm install and define the second job as downstream. result-test is the second job, which will run npm test as the command. These two should be triggered automatically via a PollSCM trigger scheduled to run every two minutes .","title":"Assignment - Create a pipeline for the Nodejs app"},{"location":"jenkinsfile/","text":"Pipeline as a Code with Jenkinsfile Here is what you are going to learn in this lab, You would begin by defining branch protection rules on GitHub Then you would learn about enforcing code reviews via raising pull requests You would then start learning how to write pipeline as a code Learn the syntax to write declarative Jenkins pipeline Create Jenkinsfiles for a Java and NodeJS applications And finally launch it with multi branch pipelines on Jenkins Enforcing Workflow with Branch Policies Reading List : Web: Guide to Trunk Based Development Video: Trunk Based Development Explained Lets create branch policies based on trunk based development workflow. With trunk based development, Master branch is the trunk/main line of code, which is locked. No direct checkins to master allowed. Every bugfix gets its own branch Every feature gets its own branch too Features branches are typically short lived Merges to master require pull request Further policies could be added to enforce the code review as well as integrate with jenkins ci to run per branch pipeline This is how it should look like, To define the branch policies, Goto settings for your github repository and select branches options From Branch Protection Rules section, click on Add rule button. Add the following set of rules Require Pull request reviews before merging Dismiss stale pull request approvals when new commits are pushed Require status checks to pass before merging Include Administrators The following image depict the branch protection rules Testing Branch Protection Rules You need to clone the repository to your machine if you are not cloned before. Once you have the cloned repository in your local, made some changes in your README.md file and check and commit those changes once it done by using following commands. git diff git commit -am \"test\" git push origin master Whenever you are trying to push some changes, it throws an error master protected branch hook declined , because you can't directly push to master and atleast it should be approved by at least one reviewers. Now you need to reset your commit by using previous commit id. replace YOURLASTCOMMITID with the actual commit id following git log git reset --hard YOURLASTCOMMITID Once you done hard reset, it will back to your previous commit. Code Reviews with Pull Requests With this sub section, you will learn how to make changes in master branch by using code reviews and pull requests. You'r task this time is just to update the existing README.md file to the project and incorporate those changes to the trunk i.e. master branch. Create a branch readme using command following, git checkout -b readme Running this command, git will create and switch to the readme branch. Update the README.md file by adding a description of the app. e.g. filename: README.md Example Voting App ========= This is a sample voting app. Save and commit the changes you have made. git status git commit -am \"added application info\" git push origin readme This pushes the changes to readme branch of the repo on GitHub. Now go to the github repository and choose branch readme , there you should see new pull request . The pull request is to help you to merge those changes from the feature branch to master, to the upstream repo you forked, or even to a completely differnt fork. Select new pull request and choose your base as master branch, add the description and create pull request. Add a reviewer: Creating a pull request does not allow you to merge immediately. It would demand a code review which is been manadated as part of the branch protection rules you have set. Add at least one of your collaborators as a reviewer. If you do not have a collaborator, create another account on GitHub, configure it as a collaborator, and add it as a reviewer. Request a review. If you are the reviewer, go to pull requests, review the changes and approve. After approval you could merge the pull request to master. You could delete the branch after merge. Writing Pipeline as a Code Reading List : Declarative Pipeline Syntax Declarative Pipeline Steps Following is an example pipeline code. Examine it to learn how to create a Jenkinsfile and define the jobs as a code. Some of the important directves are, Pipeline Agent Tools Stages | Stage | Steps Post Creating a sample declarative pipeline In this sub section you will learn how to create and execute a declarative pipeline. Begin by creating a sample pipeline job. To create it, go to jenkins page and select new item to create pipeline-01 job, while creating pipeline job use project as pipeline goto pipeline-01 configuration page, in pipeline step choose hello-world script and save the configuration to run the build. Once you run the build it will successfully build helloworld job. Now you are going to write declarative pipeline, visit declarative pipeline for your reference. Use the following code to configure your pipeline job. pipeline { agent any stages{ stage(one){ steps{ echo 'step 1' } } stage(two){ steps{ echo 'step 2' } } stage(three){ steps{ echo 'step 3' } } } post{ always{ echo 'This pipeline is completed..' } } } After configure the job, build it view the stage view to know how the pipeline works and how much time it will take to complete the job. Now add some additional step like sleep time with the same job, refer following code for the configuration. Save the configuration and build the job for the result. pipeline { agent any stages{ stage(one){ steps{ echo 'step 1' sleep 3 } } stage(two){ steps{ echo 'step 2' sleep 9 } } stage(three){ steps{ echo 'step 3' sleep 5 } } } post{ always{ echo 'This pipeline is completed..' } } } you could see the time interval between each steps in stage view and select to see a specific stage logs. Jenkinsfile for a Java App With this section, your will define pipeline as a code for a java worker app which uses maven as a build tool. Create new feature/workerpipe branch, by using following command, git checkout -b feature/workerpipe git branch Now you are going to write Jenkinsfile for worker application using previous sample code the following steps to write Jenkinsfile. Steps: Create a Jenkisfile inside worker dir of your code. Before you start writing the code, check your maven version in your jenkins Manage Jenkins --> Global Tools Configurations -> Maven and note down the exact name you are referring to the configuration (e.g. Maven 3.6.2). file: worker/Jenkinsfile pipeline { agent any tools{ maven 'Maven 3.6.2' } stages{ stage(\"build\"){ steps{ echo 'Compiling worker app' dir('worker'){ sh 'mvn compile' } } } stage(two){ steps{ echo 'Running Unit Tets on worker app' } } stage(three){ steps{ echo 'Packaging worker app' } } } post{ always{ echo 'Building multibranch pipeline for worker is completed..' } } } Once you created Jenkinsfile, commit the file and push the changes to feature/workerpipe git status git add worker/Jenkisfile git commit -am \"added Jenkinsfile for worker with build job\" git push origin feature/workerpipe Multi Branch Pipeline Project With this section, you are going to create and execute a multi branch pipeline which scans your repository automatically for Jenkinsfile setup the pipeline jobs for the branches which contain the above pipeline script start executing the CI jobs Refer to the following steps to create a multi branch pipeline. Steps: Create a new job worker-pipe in your instavote directory, choose project type as multibranch pipeline. In the job configuration page, under the branch sources choose GitHub , add your account credentials, and choose the project repository. example image is given following, Under build configuration, mention your Jenkinsfile path as worker/Jenkisfile . Add periodical checks interval as 5 minutes under Scan multibranch pipeline triggers and save the configuration, it will automatically scan your repository. Whenever it detects new branch under repository, it scans and runs the pipeline build automatically. Once the pipeline run is succesful, add two more jobs in the same Jenkinsfile viz. mvn clean test and mvn package pipeline { agent any tools{ maven 'Maven 3.6.2' } stages{ stage(\"build\"){ steps{ echo 'Compiling worker app..' dir('worker'){ sh 'mvn compile' } } } stage(\"test\"){ steps{ echo 'Running Unit Tets on worker app..' dir('worker'){ sh 'mvn clean test' } } } stage(\"package\"){ steps{ echo 'Packaging worker app' dir('worker'){ sh 'mvn package' } } } } post{ always{ echo 'Building multibranch pipeline for worker is completed..' } } } After making changes in Jenkisfile, commit the file from your feature/workerpipe and push the changes into the same branch. git status git add worker/Jenkisfile git commit -am \"added Test and package job for worker pipeline\" git push origin feature/workerpipe Once you push the changes to feature/workerpipe branch, webhook/scan will automatically trigger the feature/workerpipe branch build in instavote multibranch pipeline. Now after running package, it will create jar/war file. You need to archive that artifact and for your feature use, you could download that file from jenkins. pipeline { agent any tools{ maven 'Maven 3.6.2' } stages{ stage(one){ steps{ echo 'Compiling worker app..' dir('worker'){ sh 'mvn compile' } } } stage(two){ steps{ echo 'Running Unit Tets on worker app..' dir('worker'){ sh 'mvn clean test' } } } stage(three){ steps{ echo 'Packaging worker app' dir('worker'){ sh 'mvn package -DskipTests' archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true } } } } post{ always{ echo 'Building multibranch pipeline for worker is completed..' } } } Commit the chanegs to feature/workerpipe and push to the branch. git status git add worker/Jenkisfile git commit -am \"archive artifacts, skiptest and package\" git push origin feature/workerpipe You have setup a multibranch pipeline so that the CI pipelines are run automatically for every branch that you create in future. This is extremely useful to get the feedback from CI system even before you merge the code into the trunk. This should get rid of master branch with a broken build completely. Configuring Conditional Execution of Stages As with the current configuration, the pipeline you have created will launch for any and every change committed to the repository. However, it makes sense to restrict that only to the subset of changes made for the worker application. Specially a desirable feature with mono repositories which contain multiple sub projects. You may also want to restrict certain jobs to run only on specific branches e.g. integration and acceptance tests should run only for the master branch, packaging applications to create and distribute artifacts also is relevant only for the master branch. How to achieve that is by setting up conditional execution. You are going to define following conditionbs for the worker pipline, run packaging job only on master run the jobs in this pipeline only if code in worker subdir is updated Read the description of when directive in the Jenkinsfile documentation for reference before you start refactoring the code as follows, file: worker/Jenkinsfile pipeline { agent any tools{ maven 'Maven 3.6.2' } stages{ stage(one){ when{ changeset \"**/worker/**\" } steps{ echo 'Compiling worker app..' dir('worker'){ sh 'mvn compile' } } } stage(two){ when{ changeset \"**/worker/**\" } steps{ echo 'Running Unit Tets on worker app..' dir('worker'){ sh 'mvn clean test' } } } stage(three){ when{ branch 'master' changeset \"**/worker/**\" } steps{ echo 'Packaging worker app' dir('worker'){ sh 'mvn package -DskipTests' archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true } } } } post{ always{ echo 'Building multibranch pipeline for worker is completed..' } } } Once you make changes, commit the changes to feature/workerpipe and push to GitHub. git status git add worker/Jenkisfile git commit -am \"run package step only on master, run stages only worker changes \" git push origin feature/workerpipe After making this changes, you would notice that the build it will run only for first two stages and skip package stage with artifacts. Warning: Even though Jenkinsfile is part of the worker subpath, its not considered as part of the changeset to trigger the builds. You would need to make changes to other files in order to see the jobs being triggered. You could make some changes in README.md file in root directory and commit those chanegs, push into feature/workerpipe . Build will be trigger but it will skip all three stages. You don't need this conditional build always, use git log and reset to go back your previous commit. git log git reset --hard yourlastcommitid git push origin feature/workerpipe -f Now you have learned how to use conditional pipeline stages. Assignment: Writing Jenkinsfile for result app You have been tasked to write declarative pipeline for result , a nodeJS application. Install NodeJS plugin and configure 'NodeJS 8.9.0' from Global Tools . Add two stages, build (npm install) and test (npm test) Stages should run conditionally only when there is a change to result subdir You could refer the workflow following You could reference this page to observer the solution.","title":"Lab 4 - Dev Workflow & Pipeline as a Code with Jenkinsfile"},{"location":"jenkinsfile/#pipeline-as-a-code-with-jenkinsfile","text":"Here is what you are going to learn in this lab, You would begin by defining branch protection rules on GitHub Then you would learn about enforcing code reviews via raising pull requests You would then start learning how to write pipeline as a code Learn the syntax to write declarative Jenkins pipeline Create Jenkinsfiles for a Java and NodeJS applications And finally launch it with multi branch pipelines on Jenkins","title":"Pipeline as a Code with Jenkinsfile"},{"location":"jenkinsfile/#enforcing-workflow-with-branch-policies","text":"Reading List : Web: Guide to Trunk Based Development Video: Trunk Based Development Explained Lets create branch policies based on trunk based development workflow. With trunk based development, Master branch is the trunk/main line of code, which is locked. No direct checkins to master allowed. Every bugfix gets its own branch Every feature gets its own branch too Features branches are typically short lived Merges to master require pull request Further policies could be added to enforce the code review as well as integrate with jenkins ci to run per branch pipeline This is how it should look like, To define the branch policies, Goto settings for your github repository and select branches options From Branch Protection Rules section, click on Add rule button. Add the following set of rules Require Pull request reviews before merging Dismiss stale pull request approvals when new commits are pushed Require status checks to pass before merging Include Administrators The following image depict the branch protection rules","title":"Enforcing Workflow with Branch Policies"},{"location":"jenkinsfile/#testing-branch-protection-rules","text":"You need to clone the repository to your machine if you are not cloned before. Once you have the cloned repository in your local, made some changes in your README.md file and check and commit those changes once it done by using following commands. git diff git commit -am \"test\" git push origin master Whenever you are trying to push some changes, it throws an error master protected branch hook declined , because you can't directly push to master and atleast it should be approved by at least one reviewers. Now you need to reset your commit by using previous commit id. replace YOURLASTCOMMITID with the actual commit id following git log git reset --hard YOURLASTCOMMITID Once you done hard reset, it will back to your previous commit.","title":"Testing Branch Protection Rules"},{"location":"jenkinsfile/#code-reviews-with-pull-requests","text":"With this sub section, you will learn how to make changes in master branch by using code reviews and pull requests. You'r task this time is just to update the existing README.md file to the project and incorporate those changes to the trunk i.e. master branch. Create a branch readme using command following, git checkout -b readme Running this command, git will create and switch to the readme branch. Update the README.md file by adding a description of the app. e.g. filename: README.md Example Voting App ========= This is a sample voting app. Save and commit the changes you have made. git status git commit -am \"added application info\" git push origin readme This pushes the changes to readme branch of the repo on GitHub. Now go to the github repository and choose branch readme , there you should see new pull request . The pull request is to help you to merge those changes from the feature branch to master, to the upstream repo you forked, or even to a completely differnt fork. Select new pull request and choose your base as master branch, add the description and create pull request. Add a reviewer: Creating a pull request does not allow you to merge immediately. It would demand a code review which is been manadated as part of the branch protection rules you have set. Add at least one of your collaborators as a reviewer. If you do not have a collaborator, create another account on GitHub, configure it as a collaborator, and add it as a reviewer. Request a review. If you are the reviewer, go to pull requests, review the changes and approve. After approval you could merge the pull request to master. You could delete the branch after merge.","title":"Code Reviews with Pull Requests"},{"location":"jenkinsfile/#writing-pipeline-as-a-code","text":"Reading List : Declarative Pipeline Syntax Declarative Pipeline Steps Following is an example pipeline code. Examine it to learn how to create a Jenkinsfile and define the jobs as a code. Some of the important directves are, Pipeline Agent Tools Stages | Stage | Steps Post","title":"Writing Pipeline as a Code"},{"location":"jenkinsfile/#creating-a-sample-declarative-pipeline","text":"In this sub section you will learn how to create and execute a declarative pipeline. Begin by creating a sample pipeline job. To create it, go to jenkins page and select new item to create pipeline-01 job, while creating pipeline job use project as pipeline goto pipeline-01 configuration page, in pipeline step choose hello-world script and save the configuration to run the build. Once you run the build it will successfully build helloworld job. Now you are going to write declarative pipeline, visit declarative pipeline for your reference. Use the following code to configure your pipeline job. pipeline { agent any stages{ stage(one){ steps{ echo 'step 1' } } stage(two){ steps{ echo 'step 2' } } stage(three){ steps{ echo 'step 3' } } } post{ always{ echo 'This pipeline is completed..' } } } After configure the job, build it view the stage view to know how the pipeline works and how much time it will take to complete the job. Now add some additional step like sleep time with the same job, refer following code for the configuration. Save the configuration and build the job for the result. pipeline { agent any stages{ stage(one){ steps{ echo 'step 1' sleep 3 } } stage(two){ steps{ echo 'step 2' sleep 9 } } stage(three){ steps{ echo 'step 3' sleep 5 } } } post{ always{ echo 'This pipeline is completed..' } } } you could see the time interval between each steps in stage view and select to see a specific stage logs.","title":"Creating a sample declarative pipeline"},{"location":"jenkinsfile/#jenkinsfile-for-a-java-app","text":"With this section, your will define pipeline as a code for a java worker app which uses maven as a build tool. Create new feature/workerpipe branch, by using following command, git checkout -b feature/workerpipe git branch Now you are going to write Jenkinsfile for worker application using previous sample code the following steps to write Jenkinsfile. Steps: Create a Jenkisfile inside worker dir of your code. Before you start writing the code, check your maven version in your jenkins Manage Jenkins --> Global Tools Configurations -> Maven and note down the exact name you are referring to the configuration (e.g. Maven 3.6.2). file: worker/Jenkinsfile pipeline { agent any tools{ maven 'Maven 3.6.2' } stages{ stage(\"build\"){ steps{ echo 'Compiling worker app' dir('worker'){ sh 'mvn compile' } } } stage(two){ steps{ echo 'Running Unit Tets on worker app' } } stage(three){ steps{ echo 'Packaging worker app' } } } post{ always{ echo 'Building multibranch pipeline for worker is completed..' } } } Once you created Jenkinsfile, commit the file and push the changes to feature/workerpipe git status git add worker/Jenkisfile git commit -am \"added Jenkinsfile for worker with build job\" git push origin feature/workerpipe","title":"Jenkinsfile for a Java App"},{"location":"jenkinsfile/#multi-branch-pipeline-project","text":"With this section, you are going to create and execute a multi branch pipeline which scans your repository automatically for Jenkinsfile setup the pipeline jobs for the branches which contain the above pipeline script start executing the CI jobs Refer to the following steps to create a multi branch pipeline. Steps: Create a new job worker-pipe in your instavote directory, choose project type as multibranch pipeline. In the job configuration page, under the branch sources choose GitHub , add your account credentials, and choose the project repository. example image is given following, Under build configuration, mention your Jenkinsfile path as worker/Jenkisfile . Add periodical checks interval as 5 minutes under Scan multibranch pipeline triggers and save the configuration, it will automatically scan your repository. Whenever it detects new branch under repository, it scans and runs the pipeline build automatically. Once the pipeline run is succesful, add two more jobs in the same Jenkinsfile viz. mvn clean test and mvn package pipeline { agent any tools{ maven 'Maven 3.6.2' } stages{ stage(\"build\"){ steps{ echo 'Compiling worker app..' dir('worker'){ sh 'mvn compile' } } } stage(\"test\"){ steps{ echo 'Running Unit Tets on worker app..' dir('worker'){ sh 'mvn clean test' } } } stage(\"package\"){ steps{ echo 'Packaging worker app' dir('worker'){ sh 'mvn package' } } } } post{ always{ echo 'Building multibranch pipeline for worker is completed..' } } } After making changes in Jenkisfile, commit the file from your feature/workerpipe and push the changes into the same branch. git status git add worker/Jenkisfile git commit -am \"added Test and package job for worker pipeline\" git push origin feature/workerpipe Once you push the changes to feature/workerpipe branch, webhook/scan will automatically trigger the feature/workerpipe branch build in instavote multibranch pipeline. Now after running package, it will create jar/war file. You need to archive that artifact and for your feature use, you could download that file from jenkins. pipeline { agent any tools{ maven 'Maven 3.6.2' } stages{ stage(one){ steps{ echo 'Compiling worker app..' dir('worker'){ sh 'mvn compile' } } } stage(two){ steps{ echo 'Running Unit Tets on worker app..' dir('worker'){ sh 'mvn clean test' } } } stage(three){ steps{ echo 'Packaging worker app' dir('worker'){ sh 'mvn package -DskipTests' archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true } } } } post{ always{ echo 'Building multibranch pipeline for worker is completed..' } } } Commit the chanegs to feature/workerpipe and push to the branch. git status git add worker/Jenkisfile git commit -am \"archive artifacts, skiptest and package\" git push origin feature/workerpipe You have setup a multibranch pipeline so that the CI pipelines are run automatically for every branch that you create in future. This is extremely useful to get the feedback from CI system even before you merge the code into the trunk. This should get rid of master branch with a broken build completely.","title":"Multi Branch Pipeline Project"},{"location":"jenkinsfile/#configuring-conditional-execution-of-stages","text":"As with the current configuration, the pipeline you have created will launch for any and every change committed to the repository. However, it makes sense to restrict that only to the subset of changes made for the worker application. Specially a desirable feature with mono repositories which contain multiple sub projects. You may also want to restrict certain jobs to run only on specific branches e.g. integration and acceptance tests should run only for the master branch, packaging applications to create and distribute artifacts also is relevant only for the master branch. How to achieve that is by setting up conditional execution. You are going to define following conditionbs for the worker pipline, run packaging job only on master run the jobs in this pipeline only if code in worker subdir is updated Read the description of when directive in the Jenkinsfile documentation for reference before you start refactoring the code as follows, file: worker/Jenkinsfile pipeline { agent any tools{ maven 'Maven 3.6.2' } stages{ stage(one){ when{ changeset \"**/worker/**\" } steps{ echo 'Compiling worker app..' dir('worker'){ sh 'mvn compile' } } } stage(two){ when{ changeset \"**/worker/**\" } steps{ echo 'Running Unit Tets on worker app..' dir('worker'){ sh 'mvn clean test' } } } stage(three){ when{ branch 'master' changeset \"**/worker/**\" } steps{ echo 'Packaging worker app' dir('worker'){ sh 'mvn package -DskipTests' archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true } } } } post{ always{ echo 'Building multibranch pipeline for worker is completed..' } } } Once you make changes, commit the changes to feature/workerpipe and push to GitHub. git status git add worker/Jenkisfile git commit -am \"run package step only on master, run stages only worker changes \" git push origin feature/workerpipe After making this changes, you would notice that the build it will run only for first two stages and skip package stage with artifacts. Warning: Even though Jenkinsfile is part of the worker subpath, its not considered as part of the changeset to trigger the builds. You would need to make changes to other files in order to see the jobs being triggered. You could make some changes in README.md file in root directory and commit those chanegs, push into feature/workerpipe . Build will be trigger but it will skip all three stages. You don't need this conditional build always, use git log and reset to go back your previous commit. git log git reset --hard yourlastcommitid git push origin feature/workerpipe -f Now you have learned how to use conditional pipeline stages.","title":"Configuring Conditional Execution of Stages"},{"location":"jenkinsfile/#assignment-writing-jenkinsfile-for-result-app","text":"You have been tasked to write declarative pipeline for result , a nodeJS application. Install NodeJS plugin and configure 'NodeJS 8.9.0' from Global Tools . Add two stages, build (npm install) and test (npm test) Stages should run conditionally only when there is a change to result subdir You could refer the workflow following You could reference this page to observer the solution.","title":"Assignment: Writing  Jenkinsfile for result app"},{"location":"setup/","text":"Creating learning environment In this lab, you will learn, how to install docker desktop on MacOS creating a google cloud account and optionally how to configure vm on GCP and install docker on linux vm. Install Docker Desktop on MacOS In this subsection, you would learn how to setup Docker Desktop on MacOS. However, you could follow similar instructions for Windows as well, Vist [Docker Desktop Portal](https://www.docker.com/products/docker-desktop, an official page for the software. Click on Download Desktop for Mac and for Windows button, which would take you to docker hub Use your docker hub credentials to log in and download the docker from docker hub. If you have not signed up to docker hub, its a good time to do so. Download the dockerdesktop installer form docker hub and move the docker to applications directory on mac os. Once the docker daemon start, launch a terminal and validate the docker by running the following commands on your terminal. * docker version * docker run hello world Now docker run hello world runs the smoke test and it will gives the result, so this is how you could install docker on MacOS and validate. Creating a Google Cloud Account Here you will learn how to create a google cloud account. Prerequisite for this is you should have a google account. Visit google-cloud to create a google cloud account, get started with free account and signup to get free $300 credit which is valid for whole one year. While creating account choose a account type as individual and provide your address, payment details to complete the signup. Once you create google cloud account, you will get console access. Goto the console page, there you could see profile details, notifications and left side you could see services that are provided in gcp. Now you are created your first GCP account, goto your gmail & complete your profile info and get start working on VM.","title":"Creating learning environment"},{"location":"setup/#creating-learning-environment","text":"In this lab, you will learn, how to install docker desktop on MacOS creating a google cloud account and optionally how to configure vm on GCP and install docker on linux vm.","title":"Creating learning environment"},{"location":"setup/#install-docker-desktop-on-macos","text":"In this subsection, you would learn how to setup Docker Desktop on MacOS. However, you could follow similar instructions for Windows as well, Vist [Docker Desktop Portal](https://www.docker.com/products/docker-desktop, an official page for the software. Click on Download Desktop for Mac and for Windows button, which would take you to docker hub Use your docker hub credentials to log in and download the docker from docker hub. If you have not signed up to docker hub, its a good time to do so. Download the dockerdesktop installer form docker hub and move the docker to applications directory on mac os. Once the docker daemon start, launch a terminal and validate the docker by running the following commands on your terminal. * docker version * docker run hello world Now docker run hello world runs the smoke test and it will gives the result, so this is how you could install docker on MacOS and validate.","title":"Install Docker Desktop on MacOS"},{"location":"setup/#creating-a-google-cloud-account","text":"Here you will learn how to create a google cloud account. Prerequisite for this is you should have a google account. Visit google-cloud to create a google cloud account, get started with free account and signup to get free $300 credit which is valid for whole one year. While creating account choose a account type as individual and provide your address, payment details to complete the signup. Once you create google cloud account, you will get console access. Goto the console page, there you could see profile details, notifications and left side you could see services that are provided in gcp. Now you are created your first GCP account, goto your gmail & complete your profile info and get start working on VM.","title":"Creating a Google Cloud Account"},{"location":"tests/","text":"Continuous Testing This lab is dedicated to adding automated tests, and here are your learning objectives, You are going to begin by analysing code coverage with Jococo Learn how to improve the code coverage Setup Sonarqube to automatically scan your repository Create a project gating system to automatically decide whether the code is safe to deploy Add integration and acceptance tests with docker compose and finally, incorporate all of these into the Jenkins pipeline Code coverage with Jacoco Create a new Jenkins project which would download the following sample repository and run unit tests with a Jacoco plugin for java and display code coverage reports as follows Steps: Fork this repo: https://github.com/lfs261/maven-examples to your GitHub account/org. Install Jacoco Plugin for Jenkins [image:D6AFDCFD-A9C4-484C-8CFE-B803CCBFDF9B-298-00000F836696EA06/Screenshot 2019-08-06 at 4.57.54 PM.png] Create a maven project, provide the repo you forked as source, add maven goals to run tests on it. Use clean test as the maven goal. [image:73C69759-708B-495E-8591-E24BC55C8BF6-298-00000F6F157D2B62/Screenshot 2019-08-06 at 4.56.26 PM.png] From post build actions, choose Record Jacoco Coverage Reports [image:0A81C0B4-81E2-441C-B5E7-60C933658478-298-00000FAEB3B0828A/Screenshot 2019-08-06 at 5.00.58 PM.png] Keep all the configurations as default and save the project. [image:1FE4D7AB-0DBD-4317-8524-D31E96F3AA72-298-00000F97C2AEFE60/Screenshot 2019-08-06 at 4.59.21 PM.png] * After you build the project, you should start setting the code coverage reports being posted on the project page. [image:8E611087-9D3A-4992-AF11-B5493338B119-298-00000FC05B444F49/Screenshot 2019-08-06 at 5.02.14 PM.png] Adding Static Code Analysis with Sonarqube Steps : Setup sonarqube Install sonarqube scanner plugin for Jenkins Create token on sonarqube Add Jenkins system/global tools configuration for sonarqube Add build breaker plugin to sonarqube: https://github.com/adnovum/sonar-build-breaker/releases/download/v2.3/sonar-build-breaker-plugin-2.3.jar Launch sonarqube server with docker as docker container run -idt --name sonarqube -p 9000:9000 sonarqube:7.9-community docker ps -l You could now access Sonarqube UI using http://IPADDRESS:9000 which would look similar to follows. [image:563A0E6F-A877-4387-AA42-98DCFC096D7C-298-000008DCBEAE7E32/Screenshot 2019-08-05 at 10.37.00 PM.png] You could then explore various tabs on the Sonarqube UI. Integrate Sonarqube with Jenkins Install Sonarqube Scanner plugin for Jenkins , without a restart. [image:65D430C0-9EA0-4848-A8ED-DA6F50C8A0FC-298-000008CCF83CB009/Screenshot 2019-08-05 at 10.35.53 PM.png] Login to Sonarqube UI with the following default credentials username: admin password admin [image:2D6727DF-51D3-459C-B03B-95EA16D402A2-298-000008ED0F3EA37D/Screenshot 2019-08-05 at 10.38.12 PM.png] Once logged in, From Administration -> Security -> User select Tokens option for Administration user, and click on that. [image:41233ACC-5F69-468D-AB75-B35494FB2303-298-000009291E464999/sonar1.png] Generate a token, provide it with a name, and copy over this token, which is displayer only once. [image:A5231F9B-7774-4D3F-88CB-25185A99E635-298-0000094ADB32FCA7/Screenshot 2019-08-05 22.44.48.png] On Jenkins, go to Jenkins -> System Configurations -> SonarQube Servers [image:78DAE3B7-DFEA-4E98-A9F4-8B2C3AE00915-298-0000098525565581/Screenshot 2019-08-05 at 10.48.56 PM.png] Provide the configuration as shown above. * Check the box to enable injection of configs * Provide a name to this instance . Keep it as sonar as it would be referred to later. * Sonarqube URL * Add server authentication token to Jenkins as secret text and select it from the dropdown. Save the configuration From Jenkins -> Global Tools Configurations -> Sonarqube provide configurations as following [image:D07CA950-3B89-4FC3-BB3C-74620CA8E687-298-000009B096332469/Screenshot 2019-08-05 at 10.52.09 PM.png] While defining the name, keep it as SonarScanner which would be referred to later when you write the pipeline code. Scanning code and reporting to Sonarqube Go to the job that you created to test Jacoco code , and add one more build step to Execute Sonarqube Scanner [image:CD809182-815F-4E69-AAE4-B631FD6DD832-298-000009ED09019527/Screenshot 2019-08-05 22.56.23.png] You could add the following snippet as Analysis Properties # Required metadata sonar.projectKey=Jacoco sonar.projectName=Jacoco Code Coverage sonar.projectVersion=1.0 # Comma-separated paths to directories with sources (required) sonar.sources=code-coverage-jacoco # Encoding of the source files sonar.sourceEncoding=UTF-8 sonar.java.binaries=. sonar.jacoco.reportPaths=code-coverage-jacoco/target/coverage-reports/jacoco-ut.exec Save and run the project. If the job succeeds, you should be able to see an output similar to the following diagram on Projects section of Sonarqube. [image:8602AC5D-B5FB-489E-8B7B-C9AF8C17B67B-298-00000A01B6E26459/Screenshot 2019-08-05 at 10.57.54 PM.png] Configuring Project Gating System From Sonarqube -> Quality Gates click on Create. [image:0FC0FF20-7410-4B46-B7FA-08053E04C0DA-298-00000A36ADEAAE6B/Screenshot 2019-08-05 at 11.01.44 PM.png] Select a criteria as shown in the image above which includes, * Code Coverage should be higher than 75% * Security Rating should be A Apply it to the project which is been added to sonarqube by searching and selecting it e.g. the one starting with Jacoco . Run the test job again, and see what happens on Jenkins as well as on Sonarqube. Did the Project Gate Pass ? Did Jenkins project fail ? Breaking Jenkins build When the project gate fails on Sonarqube, the build should break on Jenkins as well so that the pipeline execution does not proceed and deploy and faulty code. To achieve this, build breaker plugin needs to be installed on sonarqube. Follow the steps below to do so, docker exec -it sonarqube bash cd extensions/plugins wget -c https://github.com/adnovum/sonar-build-breaker/releases/download/v2.3/sonar-build-breaker-plugin-2.3.jar exit docker restart sonarqube Once Sonarqube is restarted, run the Jenkins job again, this time it should fail. Improving Code Coverage You may have already forked https://github.com/lfs261/maven-examples and created projects to test it and publish jacoco reports. Merge ut1 branches into master and run the test job again Merge ut2 branches into master and run the test job again Launch the job which runs sonarqube scanner every time you merge the branch, and observe the behaviour. Adding Sonarqube Scanner Stage to Jenkinsfile [optional] Add the following code snippet to the consolidated Jenkinsfile created earlier while setting up a monopipe. file: Jenkinsfile stage('Sonarqube') { agent any when{ branch 'master' } environment{ sonarpath = tool 'SonarScanner' } steps { echo 'Running Sonarqube Analysis..' withSonarQubeEnv('sonar') { sh \"${sonarpath}/bin/sonar-scanner -Dproject.settings=sonar-project.properties\" } } } Once you run the pipeline after adding this stage, you should be able to browse to Instavote AIO project now added to Sonarqube. [image:79DA97EE-EFA8-472F-B26E-9C8045874AB1-298-0000105849CF58DB/Screenshot 2019-08-06 at 5.13.09 PM.png] You could further configure and apply a project gate for the instate application. Adding Integration Tests Integration tests for the vote python app is already added to the vote/ subdirectory of the repository. To add integration tests to the pipeline, follow the steps below Steps : Examine the script at vote/integration_test.sh in the example-voting-app repository. Reading the script and the docker compose setup it uses, should give you a good understanding of how integration tests are setup. You could also refer to the video lessons to get a better understanding of it. Add a stage to Jenkinsfile to run the integration tests as follows file: Jenkinsfile stage('vote integration'){ agent any when{ changeset \"**/vote/**\" branch 'master' } steps{ echo 'Running Integration Tests on vote app' dir('vote'){ sh 'integration_test.sh' } } } Adding Acceptance/e2e Tests Examine the script at e2e.sh in the example-voting-app repository. Reading the script and the docker compose setup it uses, should give you a good understanding of how acceptance tests are setup. You could also refer to the video lessons to get a better understanding of it. Create a independent Jenkins Project which clones the example-voting-app repository and launches e2e tests. This would be later integrated as part of the deployment process.","title":"Lab 8 - Adding Automated Testing"},{"location":"tests/#continuous-testing","text":"This lab is dedicated to adding automated tests, and here are your learning objectives, You are going to begin by analysing code coverage with Jococo Learn how to improve the code coverage Setup Sonarqube to automatically scan your repository Create a project gating system to automatically decide whether the code is safe to deploy Add integration and acceptance tests with docker compose and finally, incorporate all of these into the Jenkins pipeline","title":"Continuous Testing"},{"location":"tests/#code-coverage-with-jacoco","text":"Create a new Jenkins project which would download the following sample repository and run unit tests with a Jacoco plugin for java and display code coverage reports as follows Steps: Fork this repo: https://github.com/lfs261/maven-examples to your GitHub account/org. Install Jacoco Plugin for Jenkins [image:D6AFDCFD-A9C4-484C-8CFE-B803CCBFDF9B-298-00000F836696EA06/Screenshot 2019-08-06 at 4.57.54 PM.png] Create a maven project, provide the repo you forked as source, add maven goals to run tests on it. Use clean test as the maven goal. [image:73C69759-708B-495E-8591-E24BC55C8BF6-298-00000F6F157D2B62/Screenshot 2019-08-06 at 4.56.26 PM.png] From post build actions, choose Record Jacoco Coverage Reports [image:0A81C0B4-81E2-441C-B5E7-60C933658478-298-00000FAEB3B0828A/Screenshot 2019-08-06 at 5.00.58 PM.png] Keep all the configurations as default and save the project. [image:1FE4D7AB-0DBD-4317-8524-D31E96F3AA72-298-00000F97C2AEFE60/Screenshot 2019-08-06 at 4.59.21 PM.png] * After you build the project, you should start setting the code coverage reports being posted on the project page. [image:8E611087-9D3A-4992-AF11-B5493338B119-298-00000FC05B444F49/Screenshot 2019-08-06 at 5.02.14 PM.png]","title":"Code coverage with Jacoco"},{"location":"tests/#adding-static-code-analysis-with-sonarqube","text":"Steps : Setup sonarqube Install sonarqube scanner plugin for Jenkins Create token on sonarqube Add Jenkins system/global tools configuration for sonarqube Add build breaker plugin to sonarqube: https://github.com/adnovum/sonar-build-breaker/releases/download/v2.3/sonar-build-breaker-plugin-2.3.jar","title":"Adding Static Code Analysis with Sonarqube"},{"location":"tests/#launch-sonarqube-server-with-docker-as","text":"docker container run -idt --name sonarqube -p 9000:9000 sonarqube:7.9-community docker ps -l You could now access Sonarqube UI using http://IPADDRESS:9000 which would look similar to follows. [image:563A0E6F-A877-4387-AA42-98DCFC096D7C-298-000008DCBEAE7E32/Screenshot 2019-08-05 at 10.37.00 PM.png] You could then explore various tabs on the Sonarqube UI.","title":"Launch sonarqube server with docker as"},{"location":"tests/#integrate-sonarqube-with-jenkins","text":"Install Sonarqube Scanner plugin for Jenkins , without a restart. [image:65D430C0-9EA0-4848-A8ED-DA6F50C8A0FC-298-000008CCF83CB009/Screenshot 2019-08-05 at 10.35.53 PM.png] Login to Sonarqube UI with the following default credentials username: admin password admin [image:2D6727DF-51D3-459C-B03B-95EA16D402A2-298-000008ED0F3EA37D/Screenshot 2019-08-05 at 10.38.12 PM.png] Once logged in, From Administration -> Security -> User select Tokens option for Administration user, and click on that. [image:41233ACC-5F69-468D-AB75-B35494FB2303-298-000009291E464999/sonar1.png] Generate a token, provide it with a name, and copy over this token, which is displayer only once. [image:A5231F9B-7774-4D3F-88CB-25185A99E635-298-0000094ADB32FCA7/Screenshot 2019-08-05 22.44.48.png] On Jenkins, go to Jenkins -> System Configurations -> SonarQube Servers [image:78DAE3B7-DFEA-4E98-A9F4-8B2C3AE00915-298-0000098525565581/Screenshot 2019-08-05 at 10.48.56 PM.png] Provide the configuration as shown above. * Check the box to enable injection of configs * Provide a name to this instance . Keep it as sonar as it would be referred to later. * Sonarqube URL * Add server authentication token to Jenkins as secret text and select it from the dropdown. Save the configuration From Jenkins -> Global Tools Configurations -> Sonarqube provide configurations as following [image:D07CA950-3B89-4FC3-BB3C-74620CA8E687-298-000009B096332469/Screenshot 2019-08-05 at 10.52.09 PM.png] While defining the name, keep it as SonarScanner which would be referred to later when you write the pipeline code.","title":"Integrate Sonarqube with Jenkins"},{"location":"tests/#scanning-code-and-reporting-to-sonarqube","text":"Go to the job that you created to test Jacoco code , and add one more build step to Execute Sonarqube Scanner [image:CD809182-815F-4E69-AAE4-B631FD6DD832-298-000009ED09019527/Screenshot 2019-08-05 22.56.23.png] You could add the following snippet as Analysis Properties # Required metadata sonar.projectKey=Jacoco sonar.projectName=Jacoco Code Coverage sonar.projectVersion=1.0 # Comma-separated paths to directories with sources (required) sonar.sources=code-coverage-jacoco # Encoding of the source files sonar.sourceEncoding=UTF-8 sonar.java.binaries=. sonar.jacoco.reportPaths=code-coverage-jacoco/target/coverage-reports/jacoco-ut.exec Save and run the project. If the job succeeds, you should be able to see an output similar to the following diagram on Projects section of Sonarqube. [image:8602AC5D-B5FB-489E-8B7B-C9AF8C17B67B-298-00000A01B6E26459/Screenshot 2019-08-05 at 10.57.54 PM.png]","title":"Scanning code and reporting to Sonarqube"},{"location":"tests/#configuring-project-gating-system","text":"From Sonarqube -> Quality Gates click on Create. [image:0FC0FF20-7410-4B46-B7FA-08053E04C0DA-298-00000A36ADEAAE6B/Screenshot 2019-08-05 at 11.01.44 PM.png] Select a criteria as shown in the image above which includes, * Code Coverage should be higher than 75% * Security Rating should be A Apply it to the project which is been added to sonarqube by searching and selecting it e.g. the one starting with Jacoco . Run the test job again, and see what happens on Jenkins as well as on Sonarqube. Did the Project Gate Pass ? Did Jenkins project fail ?","title":"Configuring Project Gating System"},{"location":"tests/#breaking-jenkins-build","text":"When the project gate fails on Sonarqube, the build should break on Jenkins as well so that the pipeline execution does not proceed and deploy and faulty code. To achieve this, build breaker plugin needs to be installed on sonarqube. Follow the steps below to do so, docker exec -it sonarqube bash cd extensions/plugins wget -c https://github.com/adnovum/sonar-build-breaker/releases/download/v2.3/sonar-build-breaker-plugin-2.3.jar exit docker restart sonarqube Once Sonarqube is restarted, run the Jenkins job again, this time it should fail.","title":"Breaking Jenkins build"},{"location":"tests/#improving-code-coverage","text":"You may have already forked https://github.com/lfs261/maven-examples and created projects to test it and publish jacoco reports. Merge ut1 branches into master and run the test job again Merge ut2 branches into master and run the test job again Launch the job which runs sonarqube scanner every time you merge the branch, and observe the behaviour.","title":"Improving  Code Coverage"},{"location":"tests/#adding-sonarqube-scanner-stage-to-jenkinsfile-optional","text":"Add the following code snippet to the consolidated Jenkinsfile created earlier while setting up a monopipe. file: Jenkinsfile stage('Sonarqube') { agent any when{ branch 'master' } environment{ sonarpath = tool 'SonarScanner' } steps { echo 'Running Sonarqube Analysis..' withSonarQubeEnv('sonar') { sh \"${sonarpath}/bin/sonar-scanner -Dproject.settings=sonar-project.properties\" } } } Once you run the pipeline after adding this stage, you should be able to browse to Instavote AIO project now added to Sonarqube. [image:79DA97EE-EFA8-472F-B26E-9C8045874AB1-298-0000105849CF58DB/Screenshot 2019-08-06 at 5.13.09 PM.png] You could further configure and apply a project gate for the instate application.","title":"Adding Sonarqube Scanner  Stage to  Jenkinsfile [optional]"},{"location":"tests/#adding-integration-tests","text":"Integration tests for the vote python app is already added to the vote/ subdirectory of the repository. To add integration tests to the pipeline, follow the steps below Steps : Examine the script at vote/integration_test.sh in the example-voting-app repository. Reading the script and the docker compose setup it uses, should give you a good understanding of how integration tests are setup. You could also refer to the video lessons to get a better understanding of it. Add a stage to Jenkinsfile to run the integration tests as follows file: Jenkinsfile stage('vote integration'){ agent any when{ changeset \"**/vote/**\" branch 'master' } steps{ echo 'Running Integration Tests on vote app' dir('vote'){ sh 'integration_test.sh' } } }","title":"Adding Integration Tests"},{"location":"tests/#adding-acceptancee2e-tests","text":"Examine the script at e2e.sh in the example-voting-app repository. Reading the script and the docker compose setup it uses, should give you a good understanding of how acceptance tests are setup. You could also refer to the video lessons to get a better understanding of it. Create a independent Jenkins Project which clones the example-voting-app repository and launches e2e tests. This would be later integrated as part of the deployment process.","title":"Adding Acceptance/e2e Tests"},{"location":"solutions/jenkinsfile-nodejs/","text":"Writing jenkinsfile for a NodeJS app :- Here you will verify your declarative pipeline for result and if you have any doubts to create Jenkinsfile for result, follow the below steps to complete the pipeline. Steps Create a branch feature/resultpipe using git checkout command. git checkout -b feature/resultpipe Create a Jenkinsfile inside result directory or copy the previous Jenkinsfile file from worker to result. In Jenkinsfile, add nodejs tools with exact version that configured in manage jenkins -> global tool configuration -> Nodejs . file: result/Jenkinsfile pipeline { agent any tools{ nodejs 'NodeJS 8.9.0' } stages{ stage(build){ when{ changeset \"**/result/**\" } steps{ echo 'Compiling result app..' dir('worker'){ sh 'npm install' } } } stage(test){ when{ changeset \"**/result/**\" } steps{ echo 'Running Unit Tets on result app..' dir('result'){ sh 'npm test' } } } } post{ always{ echo 'Building multibranch pipeline for worker is completed..' } } } commit the changes into feature/resultpipe branch by using below commands and it will automatically git status git add feature/resultpipe git commit -am \"adding Jenkinsfile for result app\" git push origin feature/resultpipe In your jenkins, create new multibranch pipeline as result-pipe and copy form worker-pipe . go to your result-pipe configuration page add description as instavote result multi branch pipeline and under build configuration change the script path as result/Jenkinsfile and save the configiuration, it will start scaning your repository and start your build as well. go to result/test/mock.test.js file, add the one more more mocktest form exiting mocktest. commit the changes to feature/resultpipe branch using below commands. git status git add feature/resultpipe git commit -am \"adding mock test\" git push origin feature/resultpipe Once you commit changes into the branch, it will automatically build the pipeline and gives the result. Now create a pull request from main github account and have it reviewed, merge with master branch. Once merged, jenkins will run pipeline job for master branch as well.","title":"Jenkinsfile nodejs"},{"location":"solutions/jenkinsfile-nodejs/#writing-jenkinsfile-for-a-nodejs-app-","text":"Here you will verify your declarative pipeline for result and if you have any doubts to create Jenkinsfile for result, follow the below steps to complete the pipeline.","title":"Writing jenkinsfile for a NodeJS app :-"},{"location":"solutions/jenkinsfile-nodejs/#steps","text":"Create a branch feature/resultpipe using git checkout command. git checkout -b feature/resultpipe Create a Jenkinsfile inside result directory or copy the previous Jenkinsfile file from worker to result. In Jenkinsfile, add nodejs tools with exact version that configured in manage jenkins -> global tool configuration -> Nodejs . file: result/Jenkinsfile pipeline { agent any tools{ nodejs 'NodeJS 8.9.0' } stages{ stage(build){ when{ changeset \"**/result/**\" } steps{ echo 'Compiling result app..' dir('worker'){ sh 'npm install' } } } stage(test){ when{ changeset \"**/result/**\" } steps{ echo 'Running Unit Tets on result app..' dir('result'){ sh 'npm test' } } } } post{ always{ echo 'Building multibranch pipeline for worker is completed..' } } } commit the changes into feature/resultpipe branch by using below commands and it will automatically git status git add feature/resultpipe git commit -am \"adding Jenkinsfile for result app\" git push origin feature/resultpipe In your jenkins, create new multibranch pipeline as result-pipe and copy form worker-pipe . go to your result-pipe configuration page add description as instavote result multi branch pipeline and under build configuration change the script path as result/Jenkinsfile and save the configiuration, it will start scaning your repository and start your build as well. go to result/test/mock.test.js file, add the one more more mocktest form exiting mocktest. commit the changes to feature/resultpipe branch using below commands. git status git add feature/resultpipe git commit -am \"adding mock test\" git push origin feature/resultpipe Once you commit changes into the branch, it will automatically build the pipeline and gives the result. Now create a pull request from main github account and have it reviewed, merge with master branch. Once merged, jenkins will run pipeline job for master branch as well.","title":"Steps"}]}